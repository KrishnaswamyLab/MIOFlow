{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# MIOFlow — Embryoid Body Data: Preprocessing & Trajectory Inference\n",
    "\n",
    "This notebook walks through the **complete pipeline** for the Embryoid Body (EB) scRNA-seq dataset:\n",
    "\n",
    "1. Download the raw 10X data from [Mendeley Datasets](https://data.mendeley.com/datasets/v6n743h5ng/)\n",
    "2. Preprocess the data (QC filtering, normalisation, sqrt transform)\n",
    "3. Embed into PCA and PHATE latent spaces\n",
    "4. Train MIOFlow to infer developmental trajectories\n",
    "5. Decode trajectories back to gene space to obtain gene expression trends\n",
    "\n",
    "> **Dataset reference:** Moon et al. (2019), *Visualizing structure and transitions in high-dimensional biological data*, Nature Biotechnology. Data available at [Mendeley Datasets (v6n743h5ng)](https://data.mendeley.com/datasets/v6n743h5ng/).\n",
    ">\n",
    "> **MIOFlow reference:** Huguet et al. (2022), *Manifold Interpolating Optimal-Transport Flows for Trajectory Inference*, NeurIPS. [arXiv:2206.14928](https://arxiv.org/abs/2206.14928)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-md",
   "metadata": {},
   "source": "## 0. Installation\n\nRun the cell below once to install all required packages."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": "!pip install mioflow phate"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-widgets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive widgets in Google Colab\n",
    "try:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f'Running in Google Colab: {IN_COLAB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-md",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport urllib.request\nimport zipfile\nimport shutil\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport scanpy as sc\nimport phate\nimport torch\n\nfrom MIOFlow.mioflow import MIOFlow\nfrom MIOFlow.plots import plot_losses\nfrom MIOFlow.utils import set_seeds\n\nset_seeds(0)\n\nuse_cuda = torch.cuda.is_available()\nprint(f'Using CUDA: {use_cuda}')"
  },
  {
   "cell_type": "markdown",
   "id": "download-md",
   "metadata": {},
   "source": [
    "## 2. Download the Embryoid Body Data\n",
    "\n",
    "The raw scRNA-seq data is publicly available on [Mendeley Datasets (v6n743h5ng)](https://data.mendeley.com/datasets/v6n743h5ng/).\n",
    "\n",
    "The dataset contains five 10X Genomics samples collected at different time points:\n",
    "\n",
    "| Folder   | Time point   |\n",
    "|----------|--------------|\n",
    "| `T0_1A`  | Day 00–03    |\n",
    "| `T2_3B`  | Day 06–09    |\n",
    "| `T4_5C`  | Day 12–15    |\n",
    "| `T6_7D`  | Day 18–21    |\n",
    "| `T8_9E`  | Day 24–27    |\n",
    "\n",
    "Each folder contains `barcodes.tsv`, `genes.tsv`, and `matrix.mtx` files as produced by CellRanger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": "RAW_DATA_DIR = 'data/raw/scRNAseq'\nEXPECTED_DIRS = ['T0_1A', 'T2_3B', 'T4_5C', 'T6_7D', 'T8_9E']\n\ndef data_already_downloaded(base_dir, expected_dirs):\n    return all(os.path.isdir(os.path.join(base_dir, d)) for d in expected_dirs)\n\nif data_already_downloaded(RAW_DATA_DIR, EXPECTED_DIRS):\n    print('Data already present — skipping download.')\nelse:\n    os.makedirs(RAW_DATA_DIR, exist_ok=True)\n\n    url = 'https://data.mendeley.com/public-api/zip/v6n743h5ng/download/1'\n    zip_file = os.path.join(RAW_DATA_DIR, 'v6n743h5ng-1.zip')\n\n    print(f'Downloading from {url} ...')\n    req = urllib.request.Request(url, headers={\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n    })\n    with urllib.request.urlopen(req) as response, open(zip_file, 'wb') as out_file:\n        shutil.copyfileobj(response, out_file)\n\n    # Extract outer zip to a temp directory\n    temp_extract = os.path.join(RAW_DATA_DIR, 'temp_extract')\n    os.makedirs(temp_extract, exist_ok=True)\n\n    print('Extracting ...')\n    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n        zip_ref.extractall(temp_extract)\n\n    # Extract inner scRNAseq.zip if present\n    scrna_zip = os.path.join(temp_extract, 'scRNAseq.zip')\n    if os.path.exists(scrna_zip):\n        with zipfile.ZipFile(scrna_zip, 'r') as zip_ref:\n            zip_ref.extractall(temp_extract)\n\n    # Move sample directories to RAW_DATA_DIR\n    scrna_folder = os.path.join(temp_extract, 'scRNAseq')\n    src_root = scrna_folder if os.path.exists(scrna_folder) else temp_extract\n    for item in EXPECTED_DIRS:\n        src = os.path.join(src_root, item)\n        dst = os.path.join(RAW_DATA_DIR, item)\n        if os.path.exists(src):\n            shutil.move(src, dst)\n\n    shutil.rmtree(temp_extract)\n    os.remove(zip_file)\n    print(f'Done. Data extracted to {RAW_DATA_DIR}')\n\nprint('Data directories found:')\nfor d in EXPECTED_DIRS:\n    path = os.path.join(RAW_DATA_DIR, d)\n    status = 'OK' if os.path.isdir(path) else 'MISSING'\n    print(f'  {path}  [{status}]')"
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-md",
   "metadata": {},
   "source": "## 3. Preprocessing\n\nWe follow the standard scRNA-seq preprocessing pipeline:\n\n1. Load 10X data with `scanpy` and concatenate all time points (with QC metrics)\n2. Filter cells by library size (remove top and bottom 20% per sample)\n3. Remove genes expressed in fewer than 10 cells\n4. Library-size normalise\n5. Remove dead cells (high mitochondrial RNA expression)\n6. Square-root transform"
  },
  {
   "cell_type": "markdown",
   "id": "load-10x-md",
   "metadata": {},
   "source": "### 3.1 Load 10X Data\n\n`sc.read_10x_mtx` reads each CellRanger output directory directly into an AnnData object. We label each sample with its time point, concatenate all samples, then compute QC metrics — including the fraction of mitochondrial gene counts needed for dead-cell removal later."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-10x",
   "metadata": {},
   "outputs": [],
   "source": "samples = ['T0_1A', 'T2_3B', 'T4_5C', 'T6_7D', 'T8_9E']\nlabels  = ['Day 00-03', 'Day 06-09', 'Day 12-15', 'Day 18-21', 'Day 24-27']\n\nadatas = []\nfor sample, label in zip(samples, labels):\n    adata_sample = sc.read_10x_mtx(\n        os.path.join(RAW_DATA_DIR, sample),\n        var_names='gene_symbols',\n        make_unique=True,\n        cache=True,\n    )\n    adata_sample.obs['time_label'] = label\n    adatas.append(adata_sample)\n\nadata = sc.concat(adatas, merge='same')\nadata.obs_names_make_unique()\n\n# Compute QC metrics (library size, mitochondrial gene fraction)\nadata.var['mt'] = adata.var_names.str.startswith('MT-')\nsc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n\nprint('Cells per sample:')\nfor label in labels:\n    n = (adata.obs['time_label'] == label).sum()\n    print(f'  {label}: {n}')\nprint(f'\\nTotal: {adata.n_obs} cells × {adata.n_vars} genes')"
  },
  {
   "cell_type": "markdown",
   "id": "lib-size-filter-md",
   "metadata": {},
   "source": "### 3.2 Library Size Filtering\n\nWe remove cells in the top and bottom 20% of library sizes **within each sample**. This removes empty droplets and potential doublets while accounting for the fact that library size correlates with sample."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lib-size-plot",
   "metadata": {},
   "outputs": [],
   "source": "min_percentile = 20\nmax_percentile = 80\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 8))\naxes = axes.flatten()\n\nfor idx, label in enumerate(labels):\n    sample_counts = adata.obs.loc[adata.obs['time_label'] == label, 'total_counts']\n    t_min = np.percentile(sample_counts, min_percentile)\n    t_max = np.percentile(sample_counts, max_percentile)\n\n    axes[idx].hist(sample_counts, bins=50, alpha=0.7, edgecolor='black', log=True)\n    axes[idx].axvline(t_min, color='red',  linestyle='--', linewidth=2,\n                      label=f'{min_percentile}th: {t_min:.0f}')\n    axes[idx].axvline(t_max, color='blue', linestyle='--', linewidth=2,\n                      label=f'{max_percentile}th: {t_max:.0f}')\n    axes[idx].set_xlabel('Library Size (Total Counts)')\n    axes[idx].set_ylabel('Number of Cells')\n    axes[idx].set_title(label)\n    axes[idx].legend(fontsize=8)\n    axes[idx].grid(alpha=0.3)\n\naxes[-1].axis('off')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lib-size-filter",
   "metadata": {},
   "outputs": [],
   "source": "cells_to_keep = []\n\nfor label in labels:\n    sample_counts = adata.obs.loc[adata.obs['time_label'] == label, 'total_counts']\n    t_min = np.percentile(sample_counts, min_percentile)\n    t_max = np.percentile(sample_counts, max_percentile)\n    keep  = sample_counts[(sample_counts >= t_min) & (sample_counts <= t_max)].index\n    cells_to_keep.extend(keep.tolist())\n    print(f'{label}: keeping {len(keep)}/{len(sample_counts)} cells '\n          f'(range: {t_min:.0f}–{t_max:.0f})')\n\nadata = adata[cells_to_keep, :].copy()\nprint(f'\\nCells after library-size filtering: {adata.n_obs}')"
  },
  {
   "cell_type": "markdown",
   "id": "rare-genes-md",
   "metadata": {},
   "source": "### 3.3 Remove Rare Genes\n\nGenes expressed in 10 or fewer cells are unlikely to be biologically informative and are removed."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rare-genes",
   "metadata": {},
   "outputs": [],
   "source": "sc.pp.filter_genes(adata, min_cells=10)\nprint(f'Genes after rare-gene filtering: {adata.n_vars}')"
  },
  {
   "cell_type": "markdown",
   "id": "normalise-md",
   "metadata": {},
   "source": "### 3.4 Library-Size Normalisation\n\nDivide each cell by its total count and rescale by the median library size to make cells comparable."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalise",
   "metadata": {},
   "outputs": [],
   "source": "sc.pp.normalize_total(adata, target_sum=np.median(adata.obs['total_counts']))\nprint('Library-size normalisation complete.')"
  },
  {
   "cell_type": "markdown",
   "id": "dead-cells-md",
   "metadata": {},
   "source": "### 3.5 Remove Dead Cells\n\nDead cells show elevated mitochondrial RNA expression. We remove cells in the top 90th percentile of `pct_counts_mt`, which was already computed in step 3.1."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead-cells-plot",
   "metadata": {},
   "outputs": [],
   "source": "mito_pct       = adata.obs['pct_counts_mt']\nmito_percentile = 90\nmito_threshold  = np.percentile(mito_pct, mito_percentile)\n\nprint(f'Mitochondrial genes found: {adata.var[\"mt\"].sum()}')\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax.hist(mito_pct, bins=50, alpha=0.7, edgecolor='black')\nax.axvline(mito_threshold, color='red', linestyle='--', linewidth=2,\n           label=f'{mito_percentile}th percentile: {mito_threshold:.1f}%')\nax.set_xlabel('Mitochondrial Gene %')\nax.set_ylabel('Number of Cells')\nax.set_title('Mitochondrial Content Distribution')\nax.legend()\nax.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead-cells-filter",
   "metadata": {},
   "outputs": [],
   "source": "adata = adata[adata.obs['pct_counts_mt'] < mito_threshold].copy()\nprint(f'Cells after dead-cell removal: {adata.n_obs}')"
  },
  {
   "cell_type": "markdown",
   "id": "sqrt-md",
   "metadata": {},
   "source": "### 3.6 Square-Root Transform\n\nWe use the square-root transform instead of log1p to stabilise variance. It has the same compressive shape as log but is stable at zero."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sqrt",
   "metadata": {},
   "outputs": [],
   "source": "import scipy.sparse as sp\nadata.X = np.sqrt(adata.X.toarray() if sp.issparse(adata.X) else adata.X)\nprint(f'Preprocessing complete. Final matrix: {adata.n_obs} cells × {adata.n_vars} genes')"
  },
  {
   "cell_type": "markdown",
   "id": "anndata-md",
   "metadata": {},
   "source": "## 4. AnnData Summary\n\nAll preprocessing is complete. The AnnData object is ready for dimensionality reduction."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anndata",
   "metadata": {},
   "outputs": [],
   "source": "print(adata)"
  },
  {
   "cell_type": "markdown",
   "id": "pca-md",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction\n",
    "\n",
    "### 5.1 PCA\n",
    "\n",
    "We first reduce to 50 principal components to denoise and speed up the subsequent PHATE embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata, n_comps=50)\n",
    "print(f'PCA embedding shape: {adata.obsm[\"X_pca\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phate-md",
   "metadata": {},
   "source": [
    "### 5.2 PHATE\n",
    "\n",
    "PHATE (Potential of Heat-diffusion for Affinity-based Trajectory Embedding) preserves both local and global manifold structure, making it well suited for trajectory inference. We run it on the PCA embedding.\n",
    "\n",
    "This step can take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phate",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_op = phate.PHATE(n_components=2, n_jobs=-2)\n",
    "X_phate = phate_op.fit_transform(adata.obsm['X_pca'])\n",
    "\n",
    "adata.obsm['X_phate'] = X_phate\n",
    "print(f'PHATE embedding shape: {adata.obsm[\"X_phate\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phate-plot",
   "metadata": {},
   "outputs": [],
   "source": "sc.pl.embedding(\n    adata, basis='phate', color='time_label',\n    cmap='Spectral', title='Embryoid Body — PHATE embedding',\n)"
  },
  {
   "cell_type": "markdown",
   "id": "mioflow-prep-md",
   "metadata": {},
   "source": [
    "## 6. Prepare Data for MIOFlow\n",
    "\n",
    "MIOFlow expects a DataFrame with:\n",
    "- One column per embedding dimension (`d1`, `d2`, …)\n",
    "- A `samples` column with an **integer** time-bin label for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mioflow-prep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create integer time bins: Day 00-03 → 0, Day 06-09 → 1, …, Day 24-27 → 4\n",
    "adata.obs['discrete_time'], _ = pd.factorize(adata.obs['time_label'])\n",
    "\n",
    "# Build the input DataFrame (PHATE dims + samples column)\n",
    "n_phate = adata.obsm['X_phate'].shape[1]\n",
    "mioflow_df = pd.DataFrame(\n",
    "    adata.obsm['X_phate'],\n",
    "    columns=[f'd{i}' for i in range(1, n_phate + 1)],\n",
    ")\n",
    "mioflow_df['samples'] = adata.obs['discrete_time'].values\n",
    "\n",
    "print(mioflow_df.head())\n",
    "print(f'\\nTime bins: {sorted(mioflow_df[\"samples\"].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mioflow-prep-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=mioflow_df, x='d1', y='d2',\n",
    "    hue='samples', palette='viridis',\n",
    "    s=3, ax=ax,\n",
    ")\n",
    "ax.set_title('PHATE embedding coloured by discrete time bin')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mioflow-config-md",
   "metadata": {},
   "source": [
    "## 7. Configure MIOFlow\n",
    "\n",
    "The table below describes the most important hyperparameters.\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|---|---|---|\n",
    "| `n_epochs` | 40 | Number of global training epochs |\n",
    "| `use_density_loss` | `True` | Add a kNN-based density regulariser |\n",
    "| `lambda_density` | 20 | Weight for the density loss |\n",
    "| `sample_size` | 100 | Cells sampled per time step per batch |\n",
    "| `n_trajectories` | 100 | Number of trajectories to integrate |\n",
    "| `n_bins` | 100 | Number of time bins for ODE integration |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mioflow-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "MODEL_CONFIG = {\n",
    "    'layers': [16, 32, 16],\n",
    "    'activation': 'CELU',\n",
    "    'use_cuda': use_cuda,\n",
    "}\n",
    "\n",
    "# Training\n",
    "TRAINING_CONFIG = {\n",
    "    'n_epochs': 40,\n",
    "}\n",
    "\n",
    "# Loss\n",
    "OPTIMIZATION_CONFIG = {\n",
    "    'use_density_loss': True,\n",
    "    'lambda_density': 20,\n",
    "}\n",
    "\n",
    "# Data sampling\n",
    "DATA_CONFIG = {\n",
    "    'sample_size': 100,\n",
    "}\n",
    "\n",
    "# Output\n",
    "OUTPUT_CONFIG = {\n",
    "    'exp_dir': '.',\n",
    "    'n_trajectories': 100,\n",
    "    'n_bins': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mioflow-init-md",
   "metadata": {},
   "source": [
    "## 8. Initialise MIOFlow\n",
    "\n",
    "Pass the AnnData object, the input DataFrame, and the configuration dictionaries to `MIOFlow`. The `obsm_key` parameter tells MIOFlow which embedding to use for the trajectory inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mioflow-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "mioflow_operator = MIOFlow(\n",
    "    adata,\n",
    "    input_df=mioflow_df,\n",
    "    obsm_key='X_phate',\n",
    "    debug_level='info',\n",
    "    model_config=MODEL_CONFIG,\n",
    "    **TRAINING_CONFIG,\n",
    "    **OPTIMIZATION_CONFIG,\n",
    "    **DATA_CONFIG,\n",
    "    **OUTPUT_CONFIG,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-md",
   "metadata": {},
   "source": [
    "## 9. Train — `~5 minutes`\n",
    "\n",
    "`fit()` trains the Neural ODE end-to-end using the optimal-transport loss. Progress is printed each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "outputs": [],
   "source": [
    "mioflow = mioflow_operator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "losses-md",
   "metadata": {},
   "source": [
    "## 10. Training Losses\n",
    "\n",
    "The losses should decrease during training, indicating that the algorithm is learning to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "losses",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(\n",
    "    mioflow.local_losses,\n",
    "    mioflow.batch_losses,\n",
    "    mioflow.globe_losses,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trajectories-md",
   "metadata": {},
   "source": [
    "## 11. Visualise Trajectories\n",
    "\n",
    "`mioflow.trajectories` has shape `(n_bins, n_trajectories, n_dims)` in normalised PHATE space. We denormalise before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trajectories",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Trajectory shape (n_bins, n_trajectories, n_dims):', mioflow.trajectories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trajectories-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalise trajectories and original data back to PHATE scale\n",
    "traj_pts  = mioflow.trajectories * mioflow.std_vals + mioflow.mean_vals\n",
    "dim_cols  = [c for c in mioflow.df.columns if c != 'samples']\n",
    "true_data = mioflow.df[dim_cols].values * mioflow.std_vals + mioflow.mean_vals\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sc = ax.scatter(\n",
    "    true_data[:, 0], true_data[:, 1],\n",
    "    c=mioflow.df['samples'].values, cmap='viridis', s=1, alpha=0.5,\n",
    ")\n",
    "plt.colorbar(sc, ax=ax, label='time bin')\n",
    "\n",
    "for traj in np.transpose(traj_pts, axes=(1, 0, 2)):  # iterate over trajectories\n",
    "    ax.plot(traj[:, 0], traj[:, 1], alpha=0.5, linewidth=0.5, color='black')\n",
    "    ax.annotate(\n",
    "        '', xy=(traj[-1, 0], traj[-1, 1]), xytext=(traj[-2, 0], traj[-2, 1]),\n",
    "        arrowprops=dict(arrowstyle='->', color='black', lw=0.5, mutation_scale=10),\n",
    "    )\n",
    "\n",
    "ax.set_title('MIOFlow trajectories on PHATE embedding')\n",
    "ax.set_xlabel('PHATE 1')\n",
    "ax.set_ylabel('PHATE 2')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gene-space-md",
   "metadata": {},
   "source": [
    "## 12. Decode Trajectories to Gene Space\n",
    "\n",
    "`decode_to_gene_space()` inverts the PCA projection to recover trajectories in the original gene-expression space.\n",
    "\n",
    "The result has shape `(n_bins, n_trajectories, n_genes)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gene-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_gene_space = mioflow.decode_to_gene_space()\n",
    "print('Gene-space trajectory shape (n_bins, n_trajectories, n_genes):', trajectories_gene_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gene-trends-md",
   "metadata": {},
   "source": [
    "## 13. Gene Expression Trends\n",
    "\n",
    "### 13.1 Top Highly-Variable Genes\n",
    "\n",
    "We select the 25 most highly variable genes and plot their mean expression (± std) over all trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hvg",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, n_top_genes=25)\n",
    "example_genes    = adata.var_names[adata.var['highly_variable']]\n",
    "example_gene_mask = adata.var_names.isin(example_genes)\n",
    "print('Top 25 highly variable genes:\\n', list(example_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gene-trends",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_hvg         = adata[:, example_gene_mask]\n",
    "decoded_hvg       = trajectories_gene_space[:, :, example_gene_mask]  # (n_bins, n_traj, n_hvg)\n",
    "decoded_hvg_mean  = decoded_hvg.mean(axis=1)   # mean over trajectories → (n_bins, n_hvg)\n",
    "decoded_hvg_std   = decoded_hvg.std(axis=1)    # (n_bins, n_hvg)\n",
    "\n",
    "x_time      = np.linspace(0, 1, decoded_hvg_mean.shape[0])\n",
    "obs_time    = adata_hvg.obs['discrete_time']\n",
    "obs_time_n  = (obs_time - obs_time.min()) / (obs_time.max() - obs_time.min())\n",
    "\n",
    "import scipy.sparse as sp\n",
    "X_hvg = adata_hvg.X.toarray() if sp.issparse(adata_hvg.X) else adata_hvg.X\n",
    "data_df           = pd.DataFrame(X_hvg, columns=example_genes)\n",
    "data_df['x_time'] = obs_time_n.values\n",
    "data_mean         = data_df.groupby('x_time').mean()\n",
    "\n",
    "n_genes = decoded_hvg_mean.shape[1]\n",
    "n_cols  = 5\n",
    "n_rows  = int(np.ceil(n_genes / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, gene in enumerate(example_genes):\n",
    "    ax = axes[i]\n",
    "    ax.plot(x_time, decoded_hvg_mean[:, i], label='MIOFlow (mean)', color='tab:blue')\n",
    "    ax.fill_between(\n",
    "        x_time,\n",
    "        decoded_hvg_mean[:, i] - decoded_hvg_std[:, i],\n",
    "        decoded_hvg_mean[:, i] + decoded_hvg_std[:, i],\n",
    "        alpha=0.2, color='tab:blue',\n",
    "    )\n",
    "    if gene in data_mean.columns:\n",
    "        ax.scatter(data_mean.index, data_mean[gene], label='Observed (mean)', s=20, color='tab:orange')\n",
    "    ax.set_title(gene, fontsize=9)\n",
    "    ax.set_xlabel('Normalised time')\n",
    "    ax.legend(fontsize=7)\n",
    "\n",
    "for i in range(n_genes, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Gene Expression Trends Along MIOFlow Trajectories', fontsize=16, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-gene-md",
   "metadata": {},
   "source": [
    "### 13.2 Single Gene of Interest\n",
    "\n",
    "Replace `interest_gene` with any gene name you want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-gene",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_gene = 'CXCL3 (ENSG00000163734)'  # change this to any gene of interest\n",
    "\n",
    "gene_mask = adata.var_names.isin([interest_gene])\n",
    "if gene_mask.sum() == 0:\n",
    "    print(f\"Gene '{interest_gene}' not found. Available genes (first 10): {list(adata.var_names[:10])}\")\n",
    "else:\n",
    "    gene_data    = adata[:, gene_mask]\n",
    "    decoded_gene = trajectories_gene_space[:, :, gene_mask]   # (n_bins, n_traj, 1)\n",
    "    decoded_mean = decoded_gene.mean(axis=1).flatten()         # mean over trajectories → (n_bins,)\n",
    "    decoded_std  = decoded_gene.std(axis=1).flatten()\n",
    "\n",
    "    x_time     = np.linspace(0, 1, len(decoded_mean))\n",
    "    obs_time   = gene_data.obs['discrete_time']\n",
    "    obs_time_n = (obs_time - obs_time.min()) / (obs_time.max() - obs_time.min())\n",
    "\n",
    "    X_gene    = gene_data.X.toarray() if sp.issparse(gene_data.X) else gene_data.X\n",
    "    orig_df   = pd.DataFrame({'expr': X_gene.flatten(), 'time': obs_time_n.values})\n",
    "    orig_mean = orig_df.groupby('time')['expr'].mean()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(x_time, decoded_mean, label='MIOFlow (mean)', linewidth=2)\n",
    "    ax.fill_between(x_time, decoded_mean - decoded_std, decoded_mean + decoded_std, alpha=0.2)\n",
    "    ax.scatter(orig_mean.index, orig_mean.values, label='Observed (mean)', s=30)\n",
    "    ax.set_xlabel('Normalised time')\n",
    "    ax.set_ylabel('Expression')\n",
    "    ax.set_title(f'Gene Expression Trajectory: {interest_gene}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-traj-md",
   "metadata": {},
   "source": [
    "## 14. Analyse a Specific Trajectory\n",
    "\n",
    "Instead of averaging over all trajectories, you can focus on a single trajectory by selecting the one whose endpoint is closest to a target location in PHATE space.\n",
    "\n",
    "Update `target_x` and `target_y` to the endpoint coordinates of the trajectory you are interested in (read them from the plot in section 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-traj-select",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x = -0.006  # PHATE 1 coordinate of the desired trajectory endpoint\n",
    "target_y =  0.020  # PHATE 2 coordinate of the desired trajectory endpoint\n",
    "\n",
    "distances = [\n",
    "    np.sqrt((traj[-1, 0] - target_x) ** 2 + (traj[-1, 1] - target_y) ** 2)\n",
    "    for traj in np.transpose(traj_pts, axes=(1, 0, 2))\n",
    "]\n",
    "highlight_idx = int(np.argmin(distances))\n",
    "print(f'Selected trajectory #{highlight_idx} (distance to target: {distances[highlight_idx]:.4f})')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.scatter(true_data[:, 0], true_data[:, 1], c=mioflow.df['samples'].values, cmap='viridis', s=1, alpha=0.5)\n",
    "\n",
    "for i, traj in enumerate(np.transpose(traj_pts, axes=(1, 0, 2))):\n",
    "    colour    = 'red' if i == highlight_idx else 'black'\n",
    "    linewidth = 1.5  if i == highlight_idx else 0.4\n",
    "    alpha     = 1.0  if i == highlight_idx else 0.3\n",
    "    ax.plot(traj[:, 0], traj[:, 1], alpha=alpha, linewidth=linewidth, color=colour)\n",
    "    ax.annotate('', xy=(traj[-1, 0], traj[-1, 1]), xytext=(traj[-2, 0], traj[-2, 1]),\n",
    "                arrowprops=dict(arrowstyle='->', color=colour, lw=linewidth, mutation_scale=10))\n",
    "\n",
    "ax.plot(target_x, target_y, 'r*', markersize=12, label='target')\n",
    "ax.set_title(f'Selected trajectory #{highlight_idx}')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-traj-genes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene trends for the selected trajectory only (no averaging across trajectories)\n",
    "# trajectories_gene_space shape: (n_bins, n_traj, n_genes)\n",
    "decoded_selected = trajectories_gene_space[:, highlight_idx, :][:, example_gene_mask]  # (n_bins, n_hvg)\n",
    "\n",
    "x_time = np.linspace(0, 1, decoded_selected.shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, gene in enumerate(example_genes):\n",
    "    ax = axes[i]\n",
    "    ax.plot(x_time, decoded_selected[:, i], label=f'Traj #{highlight_idx}', color='tab:red')\n",
    "    if gene in data_mean.columns:\n",
    "        ax.scatter(data_mean.index, data_mean[gene], label='Observed (mean)', s=20, color='tab:orange')\n",
    "    ax.set_title(gene, fontsize=9)\n",
    "    ax.set_xlabel('Normalised time')\n",
    "    ax.legend(fontsize=7)\n",
    "\n",
    "for i in range(n_genes, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle(f'Gene Trends — Trajectory #{highlight_idx}', fontsize=16, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ]
}