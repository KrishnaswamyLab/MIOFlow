[
  {
    "objectID": "eval.html",
    "href": "eval.html",
    "title": "Eval",
    "section": "",
    "text": "#hide\nfrom nbdev.showdoc import *\n\n\n#export\nimport torch, numpy as np\nfrom MIOFlow.utils import sample, to_np\n\ndef generate_points(\n    model, df, n_points=100, \n    sample_with_replacement=False, use_cuda=False, \n    samples_key='samples', sample_time=None, autoencoder=None, recon=False\n):\n    '''\n    Arguments:\n    ----------\n        model (torch.nn.Module): Trained network with the property `ode` corresponding to a `NeuralODE(ODEF())`.\n            See `MIOFlow.ode` for more.\n        df (pd.DataFrame): DataFrame containing a column for the timepoint samples and the rest of the data.\n        n_points (int): Number of points to generate.\n        sample_with_replacement (bool): Defaults to `False`. Whether or not to use replacement when sampling\n            initial timepoint.\n        use_cuda (bool): Defaults to `False`. Whether or not to use cuda.\n        samples_key (str): Defaults to `'samples'`. The column in the `df` which has the timepoint groups.\n        sample_time (list | None): Defaults to `None`. If `None` uses the group numbers in order as the \n            timepoints as specified in the column `df[samples_key]`.\n        autoencoder (nn.Module|NoneType): Default to None, the trained autoencoder.\n        recon (bool): Default to 'False', whether to use the autoencoder for reconstruction.\n    Returns:\n    ----------\n        generated (float[float[]]): a list with shape `(len(sample_time), n_points, len(df.columns) - 1)`\n            of the generated points.\n    '''\n    to_torch = True if use_cuda else False\n\n    groups = sorted(df[samples_key].unique())\n    if sample_time is None:\n        sample_time = groups\n    data_t0 = sample(\n        df, np.min(groups), size=(n_points, ), \n        replace=sample_with_replacement, to_torch=to_torch, use_cuda=use_cuda\n    )\n    if autoencoder is not None and recon:\n        data_t0 = autoencoder.encoder(data_t0)\n        \n    time =  torch.Tensor(sample_time).cuda() if use_cuda else torch.Tensor(sample_time)\n    generated = model(data_t0, time, return_whole_sequence=True)\n    if autoencoder is not None and recon:\n        generated = autoencoder.decoder(generated)\n    return to_np(generated)\n\ndef generate_trajectories(\n    model, df, n_trajectories=30, n_bins=100, \n    sample_with_replacement=False, use_cuda=False, samples_key='samples',autoencoder=None, recon=False\n):\n    '''\n    Arguments:\n    ----------\n        model (torch.nn.Module): Trained network with the property `ode` corresponding to a `NeuralODE(ODEF())`.\n            See `MIOFlow.ode` for more.\n        df (pd.DataFrame): DataFrame containing a column for the timepoint samples and the rest of the data.\n        n_trajectories (int): Number of trajectories to generate.\n        n_bins (int): Number of bins to use for the trajectories. More makes it smoother. Defaults to `100`.\n        sample_with_replacement (bool): Defaults to `False`. Whether or not to use replacement when sampling\n            initial timepoint.\n        use_cuda (bool): Defaults to `False`. Whether or not to use cuda.\n        samples_key (str): Defaults to `'samples'`. The column in the `df` which has the timepoint groups.\n        autoencoder (nn.Module|NoneType): Default to None, the trained autoencoder.\n        recon (bool): Default to 'False', whether to use the autoencoder for reconstruction.\n    Returns:\n    ----------\n        trajectories (float[float[]]): a list with shape `(n_bins, n_points, len(df.columns) - 1)`\n            of the generated trajectories.\n    '''\n    groups = sorted(df[samples_key].unique())\n    sample_time = np.linspace(np.min(groups), np.max(groups), n_bins)\n    trajectories = generate_points(model, df, n_trajectories, sample_with_replacement, use_cuda, samples_key, sample_time,autoencoder=autoencoder, recon=recon)\n    return trajectories\n    \ndef generate_plot_data(\n    model, df, n_points, n_trajectories, n_bins, \n    sample_with_replacement=False, use_cuda=False, samples_key='samples',\n    logger=None, autoencoder=None, recon=False\n):\n    '''\n    Arguments:\n    ----------\n        model (torch.nn.Module): Trained network with the property `ode` corresponding to a `NeuralODE(ODEF())`.\n            See `MIOFlow.ode` for more.\n        df (pd.DataFrame): DataFrame containing a column for the timepoint samples and the rest of the data.\n        n_points (int): Number of points to generate.\n        n_trajectories (int): Number of trajectories to generate.\n        n_bins (int): Number of bins to use for the trajectories. More makes it smoother. Defaults to `100`.\n        sample_with_replacement (bool): Defaults to `False`. Whether or not to use replacement when sampling\n            initial timepoint.\n        use_cuda (bool): Defaults to `False`. Whether or not to use cuda.\n        samples_key (str): Defaults to `'samples'`. The column in the `df` which has the timepoint groups.\n        autoencoder (nn.Module|NoneType): Default to None, the trained autoencoder.\n        recon (bool): Default to 'False', whether to use the autoencoder for reconstruction.\n    Returns:\n    ----------\n        points (float[float[]]): a list with shape `(len(df[sample_key].unique()), n_points, len(df.columns) - 1)`\n            of the generated points.\n        trajectories (float[float[]]): a list with shape `(n_bins, n_points, len(df.columns) - 1)`\n            of the generated trajectories.\n    '''\n    if logger: logger.info(f'Generating points')\n    points = generate_points(model, df, n_points, sample_with_replacement, use_cuda, samples_key, None, autoencoder=autoencoder, recon=recon)\n    if logger: logger.info(f'Generating trajectories')\n    trajectories = generate_trajectories(model, df, n_trajectories, n_bins, sample_with_replacement, use_cuda, samples_key, autoencoder=autoencoder, recon=recon)\n    return points, trajectories\n\n\n#export\nimport os, logging, sklearn, pandas as pd, numpy as np\nfrom typing import Union\ntry:\n    from typing import Literal\nexcept ImportError:\n    from typing_extensions import Literal\nfrom MIOFlow.utils import generate_steps\n\ndef get_points_from_trajectories(\n    n_groups:int, \n    trajectories:Union[np.ndarray, list], \n    how:Union[Literal['start'], Literal['middle'], Literal['end']]='start', \n    logger:logging.Logger=None\n) -> np.ndarray:\n    '''\n    Arguments:\n        n_groups (int): how many time points there are total. \n        trajectories (np.ndarray | list): A list with three dimensions that correspond to:\n            `(n_bins, n_points, n_dims)`, where `n_points` are the number of points / trajectories there are,\n            `n_bins` correponds to how the trajectories were smoothed via binning (e.g. if there were 5 total\n            time points one might have 100 bins to draw a smoother line when plotting), and `n_dims` are the\n            number of dimensions the points are in (e.g. 2).\n        how (str): Defaults to `'start'`. How to extract the point for the binned trajectories.\n            If `'start'` takes the first point in the time window. If `'middle'` takes the floored averaged.\n            If `'end'` takes the the last point in the time window.\n        logger (logging.Logger): Defaults to `None`.\n    Returns:\n        points (np.ndarray): Points at the corresponding indicices. If `trajectories` has shape:\n            `(n_bins, n_points, n_dims)`, this will have shape `(n_groups, n_points, n_dims)`.\n    '''\n    # Value handling\n    _valid_how = 'start middle end'.split()\n    if how not in _valid_how:\n        raise ValueError(f'Unknown option specified for `how`. Must be in {_valid_how}')    \n        \n    if not isinstance(trajectories, np.ndarray):\n        trajectories = np.array(trajectories)\n        \n    trajectories = np.transpose(trajectories, axes=(1, 0, 2))\n    (n_points, n_bins, n_dims) = trajectories.shape\n    if logger: \n        logger.info(\n            f'Given trajectories object with {n_points} points of {n_bins} '\n            f'bins in {n_dims} dimensions.'\n        )\n    \n    parts = np.linspace(0, n_bins, n_groups + 1).astype(int).tolist()\n    steps = generate_steps(parts)\n    results = []\n    for step in steps:\n        time_window = trajectories[:, slice(*step)] \n        if how == 'start':\n            results.append(time_window[:, 0, :])\n        elif how == 'middle':\n            idx = int(np.floor(n_bins / n_groups / 2))\n            results.append(time_window[:, idx, :])\n        elif how == 'end':\n            results.append(time_window[:, -1, :])\n        else:\n            raise NotImplementedError(f'how={how} not implemented')        \n    return np.array(results)\n\n\ndef calculate_nn(\n    df:pd.DataFrame,\n    generated:Union[np.ndarray, list]=None,\n    trajectories:Union[np.ndarray, list]=None,\n    compare_to:Union[Literal['time'], Literal['any']]='time',\n    how:Union[Literal['start'], Literal['middle'], Literal['end']]='start',     \n    k:int=1,\n    groups:Union[np.ndarray, list]=None,\n    sample_key:str='samples',\n    method:str='mean',\n    logger:logging.Logger=None\n) -> float:\n    '''\n    Arguments:\n        df (pd.DataFrame): DataFrame containing all points and time sample specified by `sample_key`\n        generated (np.ndarray | list): A list of the generate points with shape \n            `(n_groups, n_points, n_dims)`, where `n_groups` is the total number of time indicies\n            as specified in `groups`.\n        trajectories (np.ndarray | list): A list with three dimensions that correspond to:\n            `(n_bins, n_points, n_dims)`, where `n_points` are the number of points / trajectories there are,\n            `n_bins` correponds to how the trajectories were smoothed via binning (e.g. if there were 5 total\n            time points one might have 100 bins to draw a smoother line when plotting), and `n_dims` are the\n            number of dimensions the points are in (e.g. 2).\n        compare_to (str): Defaults to `'time'`. Determines points to use for KNN. If `'time'` will only \n            consider points at the same time index. If `'any'` will search for nearest points regardless\n            of time.\n        how (str): Defaults to `'start'`. How to extract the point for the binned trajectories.\n            If `'start'` takes the first point in the time window. If `'middle'` takes the floored averaged.\n            If `'end'` takes the the last point in the time window.\n        k (int): Defaults to `1`. Number of points to compare predicted points in `generated` \n            or `trajectories` to.\n        groups (np.ndarray | list): Defaults to `None` and will be extracted from `df` is not provided. \n            The sorted unique values of time samples from `df` as specified by `sample_key`.\n        sample_key (str): Defaults to `'samples'`. The column in `df` which corresponds to the time index.\n        method (str): Defaults to `'mean'`. If `'mean'` returns the mean of the knn distances. If `'quartile'`\n            returns the mean of the worst (highest distances) quartile.\n        logger (logging.Logger): Defaults to `None`.\n    Returns:\n        mean_dist (float): mean distance of predicted points to the `n` nearest-neighbor points.\n    '''\n    _valid_compare_to = 'time any'.split()\n    if compare_to not in _valid_compare_to:\n        raise ValueError(f'Unknown option specified for `compare_to`. Must be in {_valid_compare_to}') \n        \n    _valid_how = 'start middle end'.split()\n    if how not in _valid_how:\n        raise ValueError(f'Unknown option specified for `how`. Must be in {_valid_how}')\n\n    _valid_method = 'mean quartile'.split()\n    if method not in _valid_method:\n        raise ValueError(f'Unknown option specified for `method`. Must be in {_valid_method}')\n        \n    if trajectories is None and generated is None:\n        raise ValueError(f'Either generated or trajectories must not be None!')\n        \n    if groups is None:\n        groups = sorted(df[sample_key].unique())\n    \n    if generated is None:\n        generated = get_points_from_trajectories(len(groups), trajectories, how, logger)\n    \n    distances = []    \n    for idx, time_sample in enumerate(sorted(groups)):            \n        pred_points = generated[idx]\n        \n        # NOTE: compare to points only at same time index\n        if compare_to == 'time':\n            true_points = df.groupby(sample_key).get_group(time_sample).drop(columns=sample_key).values\n        # NOTE: compare to any point\n        elif compare_to == 'any':\n            true_points = df.drop(columns=sample_key).values\n        else:            \n            raise NotImplementedError(f'compare_to={compare_to} not implemented')\n        true_points = true_points[:, :pred_points.shape[1]]\n        neigh = sklearn.neighbors.NearestNeighbors(n_neighbors=k)\n        neigh.fit(true_points)\n        dists, indicies = neigh.kneighbors(pred_points, return_distance=True)\n        distances.extend(dists.flatten().tolist())\n    \n    distances = np.array(distances)\n    if method == 'mean':      \n        return distances.mean()\n    elif method == 'quartile':\n        q1 = np.quantile(distances, 0.25)\n        q2 = np.quantile(distances, 0.50)\n        q3 = np.quantile(distances, 0.75)\n        \n        b1 = distances[np.where(distances < q1)]\n        b2 = distances[np.where((distances < q2) & (distances >= q1))]\n        b3 = distances[np.where((distances < q3) & (distances >= q2))]\n        b4 = distances[np.where(distances >= q3)]\n\n        return np.max([np.mean(b) for b in [b1, b2, b3, b4]])\n    else:\n        raise NotImplementedError(f'method={method} not implemented')\n\n\n#export\nfrom MIOFlow.utils import (\n    to_np, get_groups_from_df, get_cell_types_from_df, \n    get_sample_n_from_df, get_times_from_groups\n)\nimport seaborn as sns\ndef generate_tjnet_trajectories(\n    model, df, n_bins=10, use_cuda=False, samples_key='samples', \n    autoencoder=None, recon=False, where='end', start=0\n):\n    '''\n    Arguments:\n    -----------\n        model (nn.Module): Trained MIOFlow model.\n\n        df (pd.DataFrame): DataFrame of shape (n_cells, dimensions + 1), where the extra column\n            stems from a samples column (column indicating the timepoint of the cell). \n            By default the samples column is assumed to be `\"samples\"`.\n        \n        n_bins (int): For each time point split it into `n_bins` for smoother trajectories.\n            If there are `t` time points then there will be `t * n_bins` total points.\n        \n        use_cuda (bool): Whether or not to use cuda for the model and autoencoder.\n        \n        samples_key (str): The name of the column in the `df` that corresponds to the time\n            samples. Defaults to `\"samples\"`. \n        \n        autoencoder (nn.Module) Trained Geodesic Autoencoder.\n        \n        recon (bool): Whether or not to use the `autoencoder` to reconstruct the output\n            space from the `model`.\n        \n        where (str): Choices are `\"start\"`, and `\"end\"`. Defaults to `\"end\"`. Whether or not\n            to start the trajectories at `t_0` (`\"start\"`) or `t_n` (`\"end\"`). \n    \n        start (int): Defaults to `0`. Where in `generate_tjnet_trajectories` the trajectories started.\n            This is used if attempting to generate outside of `t0`. Note this works relative to `where`.\n            E.g. if `where=\"end\"` and `start=0` then this is the same as `groups[-1]`.\n\n    Returns:\n    -----------\n        trajectories (np.ndarray): Trajectories with shape (time, cells, dimensions)\n    '''\n    \n    _valid_where = 'start end'.split()\n    if where not in _valid_where:\n        raise ValueError(f'{where} not known. Should be one of {_valid_where}')\n    \n    groups = sorted(df[samples_key].unique())\n    \n    # times = groups\n    # if where == 'end':\n    #     times = times[::-1]\n    # times = times[start:]\n    \n    times = get_times_from_groups(groups, where, start)\n\n    # a, b = (np.max(groups), np.min(groups)) if where == 'end' else (np.min(groups), np.max(groups))    \n    a, b = (np.max(times), np.min(times)) if where == 'end' else (np.min(times), np.max(times))    \n    # n = -1 if where == 'end' else 0\n    n = 0 # because reversed if needed and prunned\n    \n    # sample_time = np.linspace(a, b, len(groups) * n_bins)\n    sample_time = np.linspace(a, b, len(times) * n_bins)\n    sample_time = torch.Tensor(sample_time)\n    \n    # data_tn = df[df.samples == groups[n]].drop(columns=samples_key).values    \n    data_tn = df[df.samples == times[n]].drop(columns=samples_key).values    \n    data_tn = torch.Tensor(data_tn).float()\n    \n    if use_cuda:\n        data_tn = data_tn.cuda()\n        sample_time = sample_time.cuda()\n            \n    if autoencoder is not None and recon:\n        data_tn = autoencoder.encoder(data_tn)\n\n    generated = model(data_tn, sample_time, return_whole_sequence=True)\n    if autoencoder is not None and recon:\n        generated = autoencoder.decoder(generated)\n    generated = to_np(generated)\n    return generated\n\n\ndef get_cell_indexes(\n    df, genes, trajectories, principal_components,\n    top_n=10, where='end', start=0, palette = 'viridis', \n    samples_key='samples',  samples=None,\n    cell_type_key=None, cell_types=None, use_cell_types=True\n):\n    '''\n    Notes:\n    -----------\n        - `samples` refers to the timepoint sample e.g. `samples == 1` should be Boolean array\n            corresponding to which rows in `df` that are of `t_1`.\n            \n        - `use_cell_types` determines the output shape of `top_idxs`. \n        \n            + `use_cell_types=True`: `top_idxs` is a nested dictionary with structure\n                ```\n                    {\n                        cell_type_0: {\n                            gene_0: [id_0, id_1, ... id_n]\n                        },\n                        ...\n                        cell_type_m: {...},\n                    }\n                ```\n                Where each id is a cell of the outer cell type with the highest expression of\n                the specified gene either at `t_0` (`where=\"start\"`) or `t_n` (`where=\"end\"`)\n                e.g. cell_type_0[gene_0][0] is the id of the top cell of cell type `cell_type_0`\n                expressing gene `gene_0`.\n                \n            + `use_cell_types=False`: `top_idxs` is a dictionary with structure\n                ```\n                    {                       \n                        gene_0: [id_0, id_1, ... id_n],\n                        gene_1: [id_0, id_1, ... id_n],\n                        ...\n                        gene_m: [id_0, id_1, ... id_n],                        \n                    }\n                ```\n                Where each id is a cell (of any cell type) that has the highest expression of the\n                specified gene either at `t_0` (`where=\"start\"`) or `t_n` (`where=\"end\"`).\n    \n    Arguments:\n    -----------\n        model (nn.Module): Trained MIOFlow model.\n\n        df (pd.DataFrame): DataFrame of shape (n_cells, n_genes), where the ordering of \n            the columns `n_genes` corresponds to the columns of `principle_components`.\n            It is assumed that the index of `df` are the cell types (but this need not be the case. \n            See `cell_types`). If there are additional columns (e.g. `samples_key`, `cell_type_key`)\n            should be after the gene columns.\n            \n        genes (np.ndarray | list): Genes of interest to determine which cell indexes to find.\n        \n        trajectories (np.ndarray): Trajectories with shape (time, cells, dimensions)\n        \n        principal_components (np.ndarray): The principle components with shape (dimensions, n_genes).\n            If used phate, can be obtained from `phate_operator.graph.data_pca.components_`\n        \n        top_n (int): Defaults to `10`. The number of cells to use per condition. If \n            `use_cell_types = False` this (conditions) will be the number of genes (`len(genes)`)\n            otherwise it will be the number of cell types.\n        \n        where (str): Choices are `\"start\"`, and `\"end\"`. Defaults to `\"end\"`. Whether or not\n            the trajectories start at `t_0` (`\"start\"`) or `t_n` (`\"end\"`). \n\n        start (int): Defaults to `0`. Where in `generate_tjnet_trajectories` the trajectories started.\n            This is used if attempting to generate outside of `t0`. Note this works relative to `where`.\n            E.g. if `where=\"end\"` and `start=0` then this is the same as `groups[-1]`.\n        \n        palette (str): A Matplotlib colormap. Defaults to `\"viridis\"`. \n        \n        samples_key (str): The name of the column in the `df` that corresponds to the time\n            samples. Defaults to `\"samples\"`. If `df[samples_key]` throws a `KeyError` \n            either because the `df` doesnt have this column in it or typo, will resort to\n            `samples` to determine this.\n                        \n        samples (np.ndarray | list): List of timepoints where each value corresponds to the \n            timepoint of the same row in `df`. Defaults to `None`.\n        \n        cell_type_key (str): The column name in the provided DataFrame `df` the corresponds to the \n            cell's cell types. Defaults to `None` which assumes the cell type is the index of the \n            `df i.e. `df.index`\n        \n        cell_types (np.ndarray | list): List of cell types to use from the provided DataFrame `df`.\n            Defaults to `None`. If `use_cell_types = True` will attempt to figure this out from\n            `cell_type_key`.\n        \n        use_cell_types (bool): Whether or not to use cell types.\n    \n    Returns:\n    -----------\n        genes (np.ndarray): List of genes similar to those the user passed into this function except\n            in order of the columns of the provided `df`. Any genes not found in the `df` put passed in\n            by the user will be removed.\n            \n        top_idxs (dict | dict[dict]): See notes. Dictionary or nested dictionary where leaf values are\n            indicies of cells corresponding to those expressing the highest amount of specified genes.\n            \n        inverse (np.nddary): Reconstructed gene space from `trajectories` and `principal_components`.\n            It has the shape (n_time * n_bins, n_cells, n_genes). See `generate_tjnet_trajectories`.\n        \n        colors (dict): Dictionary of either `{gene: color}` or `{cell_type: color}` depending on `use_cell_types`.\n    '''\n    # Test for valid start location\n    _valid_where = 'start end'.split()\n    if where not in _valid_where:\n        raise ValueError(f'{where} not known. Should be one of {_valid_where}')\n        \n    groups = get_groups_from_df(df, samples_key, samples)\n\n    # times = groups\n    # if where == 'end':\n    #     times = times[::-1]\n    # times = times[start:]\n\n    times = get_times_from_groups(groups, where, start)\n    \n    # Extract all of the cells at the specified either the start / end\n    n = -1 if where == 'end' else 0\n    # counts_n = get_sample_n_from_df(df, n, samples_key, samples, groups, drop_index=False)\n    counts_n = get_sample_n_from_df(df, 0, samples_key, samples, groups=times, drop_index=False)\n              \n    # Filter for only known genes\n    genes_mask = df.columns.isin(genes)\n    # Get genes in order\n    genes = df.columns[genes_mask]\n        \n    # Reconstruct full gene space (of just the genes we care about) \n    # from trajectories and principal components\n    inverse =  np.dot(trajectories, principal_components[:, genes_mask])\n                        \n    if use_cell_types:\n        # Try to correct for missing cell types if they are required\n        cell_types = get_cell_types_from_df(df, cell_type_key, cell_types)\n                \n        # Get name of cell_type_key column              \n        index = counts_n.columns[0] if cell_type_key is None else cell_type_key\n            \n        # Create colors for each cell type\n        cmap = sns.color_palette(palette, n_colors=len(cell_types))\n        colors = dict(zip(*[\n            cell_types,\n            [cmap[i] for i in range(len(cell_types))]\n        ]))\n        \n        # For each cell type and each gene get top_n cells of that cell type expressing that gene\n        top_idxs = {}\n        for cell_type in cell_types:\n            cells = counts_n[counts_n[index] == cell_type] \n            top_idxs[cell_type] = {}\n            for gene in genes:\n                top_idx = cells[gene].values.flatten().argsort()[-(top_n):]\n                top_idxs[cell_type][gene] = top_idx\n        \n        \n    else:\n        # Create colors for each gene\n        cmap = sns.color_palette(palette, n_colors=len(genes))\n        colors = dict(zip(*[\n            genes,\n            [cmap[i] for i in range(len(genes))]\n        ]))    \n            \n        # For each gene, get top_n cells expressing that gene    \n        top_idxs = {}\n        for gene in genes:\n            top_idx = counts_n[gene].values.flatten().argsort()[-(top_n):]\n            top_idxs[gene] = top_idx\n            \n        \n    return genes, top_idxs, inverse, colors"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "#hide\nfrom nbdev.showdoc import *\n\n\n#export \nimport os\nimport pandas as pd, numpy as np\nimport phate\nfrom sklearn import datasets\n\nimport seaborn as sns\nsns.color_palette(\"bright\")\nimport matplotlib as mpl\n\n\n#export\ndef construct_diamond(\n    points_per_petal:int=200,\n    petal_width:float=0.25,\n    direction:str='y'\n):\n    '''\n    Arguments:\n    ----------\n        points_per_petal (int). Defaults to `200`. Number of points per petal.\n        petal_width (float): Defaults to `0.25`. How narrow the diamonds are.\n        direction (str): Defaults to 'y'. Options `'y'` or `'x'`. Whether to make vertical\n            or horizontal diamonds.\n    Returns:\n    ---------\n        points (numpy.ndarray): the 2d array of points. \n    '''\n    n_side = int(points_per_petal/2)\n    axis_1 = np.concatenate((\n                np.linspace(0, petal_width, int(n_side/2)), \n                np.linspace(petal_width, 0, int(n_side/2))\n            ))\n    axis_2 = np.linspace(0, 1, n_side)\n    axes = (axis_1, axis_2) if direction == 'y' else (axis_2, axis_1)\n    points = np.vstack(axes).T\n    points = np.vstack((points, -1*points))\n    points = np.vstack((points, np.vstack((points[:, 0], -1*points[:, 1])).T))\n    return points\n\ndef make_diamonds(\n    points_per_petal:int=200,\n    petal_width:float=0.25,\n    colors:int=5,\n    scale_factor:float=30,\n    use_gaussian:bool=True   \n):\n    '''\n    Arguments:\n    ----------\n        points_per_petal (int). Defaults to `200`. Number of points per petal.\n        petal_width (float): Defaults to `0.25`. How narrow the diamonds are.\n        colors (int): Defaults to `5`. The number of timesteps (colors) to produce.\n        scale_factor (float): Defaults to `30`. How much to scale the noise by \n            (larger values make samller noise).\n        use_gaussian (bool): Defaults to `True`. Whether to use random or gaussian noise.\n    Returns:\n    ---------\n        df (pandas.DataFrame): DataFrame with columns `samples`, `x`, `y`, where `samples`\n            are the time index (corresponds to colors) \n    '''    \n    upper = construct_diamond(points_per_petal, petal_width, 'y')\n    lower = construct_diamond(points_per_petal, petal_width, 'x')\n    data = np.vstack((upper, lower)) \n    \n    noise_fn = np.random.randn if use_gaussian else np.random.rand\n    noise = noise_fn(*data.shape) / scale_factor\n    data = data + noise\n    df = pd.DataFrame(data, columns=['d1', 'd2'])\n    \n    c_values = np.linspace(colors, 1, colors)\n    c_thresholds = np.linspace(1, 0+1/(colors+1), colors)\n    df.insert(0, 'samples', colors)\n    df['samples'] = colors \n    for value, threshold in zip(c_values, c_thresholds):\n        index = ((np.abs(df.d1) <= threshold) & (np.abs(df.d2) <= threshold))\n        df.loc[index, 'samples'] = value\n    df.set_index('samples')\n    return df\n\n\ndf = make_diamonds(200, 0.25, 5)\nsns.scatterplot(data=df, x='d1', y='d2', hue='samples', palette='viridis')\n\n<AxesSubplot:xlabel='x', ylabel='y'>\n\n\n\n\n\n\n#export\ndef make_swiss_roll(n_points=1500):\n    '''\n    Arguments:\n    ----------\n        n_points (int): Default to `1500`. \n\n    Returns:\n    ---------\n        df (pandas.DataFrame): DataFrame with columns `samples`, `d1`, `d2`, `d3`, \n            where `samples` are the time index (corresponds to colors) \n    '''  \n    X, color = datasets.make_swiss_roll(n_samples=n_points)\n    df = pd.DataFrame(np.hstack((np.round(color).reshape(-1, 1), X)), columns='samples d1 d2 d3'.split())\n    df.samples -= np.min(df.samples)\n    return df\n\n\n#export\ndef make_tree():\n    '''\n    Arguments:\n    ----------\n        n_points (int): Default to `1500`. \n        \n    Returns:\n    ---------\n        df (pandas.DataFrame): DataFrame with columns `samples`, `d1`, `d2`, `d3`, \n            `d4`, `d5` where `samples` are the time index (corresponds to colors) \n    '''  \n    tree, branches = phate.tree.gen_dla(\n        n_dim = 200, n_branch = 10, branch_length = 300, \n        rand_multiplier = 2, seed=37, sigma = 5\n    )\n    phate_operator = phate.PHATE(n_components=5, n_jobs=-1)\n    tree_phate = phate_operator.fit_transform(tree)\n    df = pd.DataFrame(np.hstack((branches.reshape(-1, 1), tree_phate)), columns='samples d1 d2 d3 d4 d5'.split())\n    return df\n\n\n#export\nfrom MIOFlow.constants import WORM_FILE\ndef make_worm_data():\n    data = np.load(WORM_FILE)\n    sample_labels = data['sample_labels']\n    embedding = data['embedding']\n    df = pd.concat([\n            pd.DataFrame(sample_labels, columns=['samples']), \n            pd.DataFrame(embedding, columns=list(map(lambda e: f'd{e}', '12345')))\n        ], axis=1,\n    )\n    df.set_index('samples')\n    return df\n\n\n#export \nfrom MIOFlow.constants import EB_BODIES_FILE,EB_BODIES_PSEUDO_4,EB_BODIES_PSEUDO_6,EB_BODIES_PSEUDO_25,EB_BODIES_PSEUDO_82\n\ndef make_eb_data(phate=False, phate_dims=5,n_sample='all', random_state=1):\n    data = np.load(EB_BODIES_FILE)\n    sample_labels = data['sample_labels']\n    embedding = data['pca']\n    df = pd.DataFrame(embedding, columns=[f'd{i}' for i in range(1, 101)])\n    df['samples'] = sample_labels    \n    df.set_index('samples')\n    df['pt4'] = np.load(EB_BODIES_PSEUDO_4)\n    df['pt6'] = np.load(EB_BODIES_PSEUDO_6)\n    df['pt25'] = np.load(EB_BODIES_PSEUDO_25)\n    df['pt82'] = np.load(EB_BODIES_PSEUDO_82)\n    if n_sample != 'all' and not phate:\n        df = df.sample(n=n_sample,random_state=random_state)\n    \n    if phate:\n        from phate import PHATE\n        phate_operator = PHATE(phate_dims, n_jobs=-1)\n        sub_sample = df.sample(n=n_sample,random_state=random_state)\n        Y_phate = phate_operator.fit_transform(sub_sample[[f'd{i}' for i in range(1, 11)]])\n        df = pd.concat([\n        pd.DataFrame(df.samples.values, columns=['samples']), \n        pd.DataFrame(Y_phate, columns=list(map(lambda e: f'd{e}', range(1, phate_dims+1))))\n        , df['pt4'], df['pt6'], df['pt25']], axis=1)\n    return df\n\n\n#export\nfrom MIOFlow.constants import (DYNGEN_INFO_FILE, DYNGEN_EXPR_FILE)\nfrom phate import PHATE\nimport warnings\ndef make_dyngen_data(\n    time_col='sim_time', phate_dims=10, round_labels=True,\n    use_gaussian:bool=False, add_noise=False, add_noise_after_phate=False,\n    scale_factor:float=1, scale_phate=100, n_bins=5, column='d1'\n):\n    _valid = 'simulation_i step_ix sim_time'.split()\n    if time_col not in _valid:\n        time_col = _valid[0]        \n\n    noise_fn = np.random.randn if use_gaussian else np.random.rand\n    \n    \n    exp = pd.read_csv(DYNGEN_EXPR_FILE, )\n\n    if add_noise and not add_noise_after_phate:\n        noise = noise_fn(*exp.shape) / scale_factor\n        exp += noise\n\n    ids = pd.read_csv(DYNGEN_INFO_FILE, skipfooter=1, engine='python').dropna(axis=1)\n    df = pd.concat([ids, exp], axis=1).set_index('cell_id')\n    df['samples'] = df[time_col]\n    df = df.drop(columns=_valid)\n\n    phate_operator = PHATE(phate_dims, n_jobs=-1)\n    Y_phate = phate_operator.fit_transform(df.drop(columns=['samples']))\n\n    Y_phate *= scale_phate\n\n    if add_noise and add_noise_after_phate:\n        noise = noise_fn(*Y_phate.shape) / scale_factor\n        Y_phate += noise\n\n    df = pd.concat([\n        pd.DataFrame(df.samples.values, columns=['samples']), \n        pd.DataFrame(Y_phate, columns=list(map(lambda e: f'd{e}', range(1, phate_dims+1))))\n    ], axis=1)\n\n    if round_labels:\n        # instead of 0 - 1000 ----> 0 - 10\n        df.samples = np.round(df.samples, -2) / 100\n\n    df = relabel_data(df, min_bin=0, n_bins=n_bins, column=column)\n\n    if phate_dims in [2,5]:\n        locs = (df['d1'] <= -2.0)\n        df.loc[locs, 'samples'] = -1\n        df.drop(df[df['samples'] == -1].index, inplace = True)\n    elif phate_dims in [10,15,30,40,60]:\n        locs = (df['d1'] <= -1.9)\n        df.loc[locs, 'samples'] = -1\n        df.drop(df[df['samples'] == -1].index, inplace = True)\n    else:\n        warnings.warn('Not tested for this \\'phate_dims\\', using the same threshold as the one from \\'[10,15,30,40,60]\\' dims.')\n        locs = (df['d1'] <= -1.9)\n        df.loc[locs, 'samples'] = -1\n        df.drop(df[df['samples'] == -1].index, inplace = True)\n\n    return df\n\n\n\ndef relabel_data(df,min_bin=0, n_bins=10, column='d1', samples_key='samples'):\n    dff = df.copy()\n    \n    x_min = np.min(dff[column])\n    x_max = np.max(dff[column])\n    \n    parts = np.linspace(x_min, x_max, n_bins+1)\n    value = list(range(min_bin, n_bins+1, 1))\n    for i, x in list(zip(value, parts))[::-1]:\n        if i == 0:\n            continue\n        locs = (dff[column] <= x)\n        dff.loc[locs, samples_key] = i\n    return dff\n\n\n# #export\n# def relabel_data(df, n_bins=10, column='d1', samples_key='samples'):\n#     dff = df.copy()\n    \n#     x_min = np.min(dff[column])\n#     x_max = np.max(dff[column])\n    \n#     parts = np.linspace(x_min, x_max, n_bins+1)\n#     value = list(range(0, n_bins+1, 1))\n#     for i, x in list(zip(value, parts))[::-1]:\n#         if i == 0:\n#             continue\n#         locs = (dff[column] <= x)\n#         dff.loc[locs, samples_key] = i\n#     return dff\n\n\n#export\nimport numpy as np, seaborn as sns, pandas as pd, matplotlib.pyplot as plt\n\ndef rings(\n    N:int, M:int = None, \n    data_scale:float = 1, \n    add_noise:bool = True, \n    noise_scale_theta:float = 0.7, \n    noise_scale_radius:float = 0.03,\n    buffer:float = 0.8,\n    **kwargs\n) -> (np.ndarray, np.ndarray):\n    '''\n    Arguments:\n        N (int): Number of points to make.\n        M (int): Defaults to `None`. If `M='auto'` will automatically determine how many circles to make.\n        data_scale (float): Defaults to `1`. Multiplier to rescale the data.\n        add_noise (bool): Defaults to `True`. Whether or not to add noise to the data.\n        noise_scale_theta (float): Defaults to `0.7`. How much to scale the noise added to `theta`.\n        noise_scale_radius (float): Defaults to `0.3`. How much to scale the noise added to `radius`.\n        buffer (float): Defaults to `0.8`. How much to scale the `radius` to add some padding between circles.\n        **kwargs    \n        \n    Returns:\n        X (np.ndarray): The x, y coordinates for the points.\n        C (np.ndarray): The cluster number of each point.\n    '''\n    \n    \"\"\"Generate petal data set.\"\"\"\n    X = []  # points in respective petals\n    Y = []  # auxiliary array (points on outer circle)\n    C = []\n\n    assert N > 4, \"Require more than four data points\"\n\n    # Number of 'petals' to point into the data set. This is required to\n    # ensure that the full space is used.\n    if M is None:\n        M = int(np.floor(np.sqrt(N)))\n    thetas = np.linspace(0, 2 * np.pi, M, endpoint=False)\n    \n\n    for theta in thetas:\n        Y.append(np.asarray([np.cos(theta), np.sin(theta)]))\n        \n    # Radius of the smaller cycles is half of the chord distance between\n    # two 'consecutive' points on the circle.\n    radius = 0.5 * np.linalg.norm(Y[0] - Y[1])    \n\n    for i, x in enumerate(Y):\n        for theta in thetas:\n            for j in range(N // M // len(thetas)):\n                r = radius if not add_noise else radius + np.random.randn() * noise_scale_radius\n                t = theta if not add_noise else theta + np.random.randn() * noise_scale_theta\n                r *= buffer\n                X.append(np.asarray([r * np.cos(t) - x[0], r * np.sin(t) - x[1]]))\n\n                # Indicates that this point belongs to the $i$th circle.\n                C.append(i)\n    X = np.asarray(X)\n    C = np.asarray(C)\n    X *= data_scale\n    return X, C\n\ndef make_rings(N:int, M:int = None, \n    data_scale:float = 1, \n    add_noise:bool = True, \n    noise_scale_theta:float = 0.7, \n    noise_scale_radius:float = 0.03,\n    buffer:float = 0.8,\n    **kwargs\n) -> pd.DataFrame:\n    '''\n    Arguments:\n        N (int): Number of points to make.\n        M (int): Defaults to `None`. If `M='auto'` will automatically determine how many circles to make.\n        data_scale (float): Defaults to `1`. Multiplier to rescale the data.\n        add_noise (bool): Defaults to `True`. Whether or not to add noise to the data.\n        noise_scale_theta (float): Defaults to `0.7`. How much to scale the noise added to `theta`.\n        noise_scale_radius (float): Defaults to `0.3`. How much to scale the noise added to `radius`.\n        buffer (float): Defaults to `0.8`. How much to scale the `radius` to add some padding between circles.\n        **kwargs    \n        \n    Returns:\n        X (np.ndarray): The x, y coordinates for the points.\n        C (np.ndarray): The cluster number of each point.\n    '''\n    x, c = rings(N, M, data_scale, add_noise, noise_scale_theta, noise_scale_radius, buffer)\n    df = pd.DataFrame(x, columns=[f'd{i+1}' for i in range(x.shape[1])])\n    df['samples'] = c\n    df.set_index('samples')\n    return df\n\n\ndf = make_rings(\n    2000, 6,\n    data_scale = 5, \n    add_noise = True, noise_scale_theta = 0.7, \n    noise_scale_radius = 0.03,\n    buffer = 0.8,\n)\ndf.head()\n\nplt.figure(figsize=(12, 8))\nsns.scatterplot(\n    data=df, x='d1', y='d2', \n    hue='samples', palette='viridis', \n    size='samples', sizes=(100, 100), \n)\n\n<AxesSubplot:xlabel='d1', ylabel='d2'>\n\n\n\n\n\n\n#export\ndef make_jacks(\n    n_axes = 3,\n    points = 1000,\n    label_by = 'axis',\n    n_classes = 3,\n    use_neg = True,\n    data_scale = 3,\n    add_noise = True,\n    noise_scale = 0.03,\n):\n\n    _valid_label_bys = 'axis coord'.split()\n\n    if label_by not in _valid_label_bys:\n        label_by = _valid_label_bys[0]\n\n    results = []\n    classes = []\n\n    axes = np.eye(n_axes)\n\n    for i, axis in enumerate(axes):\n        segment = np.linspace(0, 1, points // n_axes).reshape(-1, 1)\n        if add_noise:\n            coordinates = axis * (segment + np.random.randn(segment.size, 1) * noise_scale)\n        else:\n            coordinates = axis * segment\n        results.extend(coordinates.tolist())\n\n        if label_by == 'axis':\n            labels = [i for j in range(len(segment))]\n            classes.extend(labels)\n        elif label_by == 'coord':\n            labels = [\n                k for k in range(n_classes)\n                for j in range(points // n_axes // n_classes)\n            ]\n            for j in range(len(segment) - len(labels)):\n                labels.append(n_classes - 1)\n            classes.extend(labels)\n\n    if use_neg:\n        for i, axis in enumerate(axes):\n            segment = np.linspace(0, 1, points // n_axes).reshape(-1, 1) * -1\n            if add_noise:\n                coordinates = axis * (segment + np.random.randn(segment.size, 1) * noise_scale)\n            else:\n                coordinates = axis * segment\n            results.extend(coordinates.tolist())\n\n            if label_by == 'axis':\n                labels = [n_axes + i  for j in range(len(segment))]\n                classes.extend(labels)\n            elif label_by == 'coord':\n                labels = [\n                    k for k in range(n_classes)\n                    for j in range(points // n_axes // n_classes)\n                ]\n                for j in range(len(segment) - len(labels)):\n                    labels.append(n_classes - 1)\n                classes.extend(labels)\n\n    results = np.array(results) + np.random.randn(len(results), n_axes) * noise_scale\n    results *= data_scale\n    df = pd.DataFrame(results, columns=[f'd{i+1}' for i in range(n_axes)])\n    df['samples'] = classes\n    df.set_index('samples')\n    return df\n\n\ndf = make_jacks(\n    n_axes = 3,\n    points = 1000,\n    label_by = 'axis',\n    n_classes = 3,\n    use_neg = True,\n    data_scale = 3,\n    add_noise = True,\n    noise_scale = 0.03,\n)\n\nfig = plt.figure(figsize=(12, 8))\nax = plt.axes(projection='3d')\nax.scatter(df.d1, df.d2, df.d3, c=df.samples)\n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection>"
  },
  {
    "objectID": "geo.html",
    "href": "geo.html",
    "title": "Geo",
    "section": "",
    "text": "DiffusionDistance\n\n DiffusionDistance (t_max=5, knn=5, anisotropy=1, log=False,\n                    normalize=False, symmetrize=False)\n\nclass DiffusionDistance\nX (np.array) data t_max (int), 2^t_max is the max scale of the Diffusion kernel knn (int) = 5 number of neighbors for the KNN in the alpha decay kernel construction, same default as in PHATE Anisotropy (int): the alpha in Coifman Lafon 2006, 1: double normalization 0: usual random walk log (bool) log(P) or not normalize (bool) min-max normalization of the distance matrix phate (bool) is PHATE op if true (should be the same as graphtool)\n\n\n\nDiffusionAffinity\n\n DiffusionAffinity (knn=5, anisotropy=0, t_diff=1, topeig=100)\n\nclass DiffusionAffinity\nX (np.array) data t_max (int), 2^t_max is the max scale of the Diffusion kernel knn (int) = 5 number of neighbors for the KNN in the alpha decay kernel construction, same default as in PHATE Anisotropy (int): the alpha in Coifman Lafon 2006, 1: double normalization 0: usual random walk t_diff (int) the power of the diffusion affinity matrix topeig (int) in the the top k eigenvalues to consider in the spectral decomposition\nreturn the l2 between the row of the affinity matrix A^t\n\n\n\nDiffusionMap\n\n DiffusionMap (knn=5, anisotropy=0, t_diff=1, topeig=100, n_emb=10)\n\nclass DiffusionMap\nX (np.array) data t_max (int), 2^t_max is the max scale of the Diffusion kernel knn (int) = 5 number of neighbors for the KNN in the alpha decay kernel construction, same default as in PHATE Anisotropy (int): the alpha in Coifman Lafon 2006, 1: double normalization 0: usual random walk t_diff (int) the power of the diffusion affinity matrix topeig (int) in the the top k eigenvalues to consider in the spectral decomposition n_emb (int) the dimension of the emb space\nreturn the pairwise dist. in the diffusion map embedding space\n\n\n\nPhateDistance\n\n PhateDistance (knn=5, anisotropy=0, verbose=False)\n\nclass PhateDistance\nX (np.array) data knn (int) = 5 number of neighbors for the KNN in the alpha decay kernel construction, same default as in PHATE Anisotropy (int): the alpha in Coifman Lafon 2006, 1: double normalization 0: usual random walk verbose (bool): verbose param. in PHATE\nreturn PHATE distance the L2 between Potential of Heat-diffusion\n\n\n\nold_DiffusionDistance\n\n old_DiffusionDistance (kernel, t_max)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\nsetup_distance\n\n setup_distance (distance_type:str='gaussian', rbf_length_scale:float=0.5,\n                 t_max:int=5, knn:int=5)"
  },
  {
    "objectID": "exp.html",
    "href": "exp.html",
    "title": "Experiment",
    "section": "",
    "text": "test_exp\n\n test_exp ()\n\n/home/solstice/anaconda3/envs/ml/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Arguments:\n  else: warn(msg)\n\n\n\nfind_exps\n\n find_exps (path, params)\n\n\n\n\nis_config_subset\n\n is_config_subset (truth, params)\n\n\n\n\nsetup_exp\n\n setup_exp (path, params, name=None)\n\n\n\n\nsave_exp_params\n\n save_exp_params (path, params, logger=None)\n\n\n\n\nload_exp_params\n\n load_exp_params (path)\n\n/home/solstice/anaconda3/envs/ml/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nReturns: \n---------- in \nReturns:\n----------...\n  else: warn(msg)\n/home/solstice/anaconda3/envs/ml/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Returns:\n  else: warn(msg)\n\n\n\ngen_exp_name\n\n gen_exp_name (name=None)\n\n/home/solstice/anaconda3/envs/ml/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nNotes: \n---------- in \nNotes:\n----------...\n  else: warn(msg)\n/home/solstice/anaconda3/envs/ml/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Notes:\n  else: warn(msg)\n\n\n\nlist_exps\n\n list_exps (path)\n\n\n\n\nexp_param_filename\n\n exp_param_filename (path)\n\n\n\n\nexp_log_filename\n\n exp_log_filename (path)\n\n\n\n\nconfig_exp_logger\n\n config_exp_logger (path)"
  },
  {
    "objectID": "plots.html",
    "href": "plots.html",
    "title": "Plots",
    "section": "",
    "text": "plot_losses\n\n plot_losses (local_losses=None, batch_losses=None, globe_losses=None,\n              save=False, path='/home/solstice/projects/MIOFlow/imgs',\n              file='losses.png')\n\n\n\n\nplot_comparision\n\n plot_comparision (df, generated, trajectories, palette='viridis',\n                   df_time_key='samples', save=False,\n                   path='/home/solstice/projects/MIOFlow/imgs',\n                   file='comparision.png', x='d1', y='d2', z='d3',\n                   is_3d=False)\n\n\n\n\nnew_plot_comparisions\n\n new_plot_comparisions (df, generated, trajectories, palette='viridis',\n                        df_time_key='samples', x='d1', y='d2', z='d3',\n                        groups=None, save=False,\n                        path='/home/solstice/projects/MIOFlow/imgs',\n                        file='comparision.png', is_3d=False)\n\n/home/solstice/anaconda3/envs/ml/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nReturns: \n---------- in \nNotes:\n    - first four arguments `genes`, `top_idxs`, `inverse`, and `colors` are output from `get_cell_indexes`...\n  else: warn(msg)\n/home/solstice/anaconda3/envs/ml/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Arguments:\n  else: warn(msg)\n/home/solstice/anaconda3/envs/ml/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Returns:\n  else: warn(msg)\n\n\n\nplot_gene_trends\n\n plot_gene_trends (genes, top_idxs, inverse, colors, samples=None,\n                   groups=None, n_cols=None, n_rows=None, where='end',\n                   start=0, top_n=None, cell_types=None,\n                   use_cell_types=True, save:bool=False,\n                   path:str='/home/solstice/projects/MIOFlow/imgs',\n                   file:str='gene_trends.png')\n\nNotes: - first four arguments genes, top_idxs, inverse, and colors are output from get_cell_indexes see that functionâ€™s docstring for more information."
  },
  {
    "objectID": "ode.html",
    "href": "ode.html",
    "title": "ODE",
    "section": "",
    "text": "#hide\nfrom nbdev.showdoc import *\n\n\n#export\nimport os, math, numpy as np\nimport torch\nimport torch.nn as nn\n\ndef ode_solve(z0, t0, t1, f):\n    \"\"\"\n    Simplest Euler ODE initial value solver\n    \"\"\"\n    h_max = 0.05\n    n_steps = math.ceil((abs(t1 - t0)/h_max).max().item())\n\n    h = (t1 - t0)/n_steps\n    t = t0\n    z = z0\n\n    for i_step in range(n_steps):\n        z = z + h * f(z, t)\n        t = t + h\n    return z\n\nclass ODEF(nn.Module):\n    def forward_with_grad(self, z, t, grad_outputs):\n        \"\"\"Compute f and a df/dz, a df/dp, a df/dt\"\"\"\n        batch_size = z.shape[0]\n\n        out = self.forward(z, t)\n\n        a = grad_outputs\n        adfdz, adfdt, *adfdp = torch.autograd.grad(\n            (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a),\n            allow_unused=True, retain_graph=True\n        )\n        # grad method automatically sums gradients for batch items, we have to expand them back \n        if adfdp is not None:\n            adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0)\n            adfdp = adfdp.expand(batch_size, -1) / batch_size\n        if adfdt is not None:\n            adfdt = adfdt.expand(batch_size, 1) / batch_size\n        return out, adfdz, adfdt, adfdp\n\n    def flatten_parameters(self):\n        p_shapes = []\n        flat_parameters = []\n        for p in self.parameters():\n            p_shapes.append(p.size())\n            flat_parameters.append(p.flatten())\n        return torch.cat(flat_parameters)\n    \nclass ODEAdjoint(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, z0, t, flat_parameters, func):\n        assert isinstance(func, ODEF)\n        bs, *z_shape = z0.size()\n        time_len = t.size(0)\n\n        with torch.no_grad():\n            z = torch.zeros(time_len, bs, *z_shape).to(z0)\n            z[0] = z0\n            for i_t in range(time_len - 1):\n                z0 = ode_solve(z0, t[i_t], t[i_t+1], func)\n                z[i_t+1] = z0\n\n        ctx.func = func\n        ctx.save_for_backward(t, z.clone(), flat_parameters)\n        return z\n\n    @staticmethod\n    def backward(ctx, dLdz):\n        \"\"\"\n        dLdz shape: time_len, batch_size, *z_shape\n        \"\"\"\n        func = ctx.func\n        t, z, flat_parameters = ctx.saved_tensors\n        time_len, bs, *z_shape = z.size()\n        n_dim = np.prod(z_shape)\n        n_params = flat_parameters.size(0)\n\n        # Dynamics of augmented system to be calculated backwards in time\n        def augmented_dynamics(aug_z_i, t_i):\n            \"\"\"\n            tensors here are temporal slices\n            t_i - is tensor with size: bs, 1\n            aug_z_i - is tensor with size: bs, n_dim*2 + n_params + 1\n            \"\"\"\n            z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim]  # ignore parameters and time\n\n            # Unflatten z and a\n            z_i = z_i.view(bs, *z_shape)\n            a = a.view(bs, *z_shape)\n            with torch.set_grad_enabled(True):\n                t_i = t_i.detach().requires_grad_(True)\n                z_i = z_i.detach().requires_grad_(True)\n                func_eval, adfdz, adfdt, adfdp = func.forward_with_grad(z_i, t_i, grad_outputs=a)  # bs, *z_shape\n                adfdz = adfdz.to(z_i) if adfdz is not None else torch.zeros(bs, *z_shape).to(z_i)\n                adfdp = adfdp.to(z_i) if adfdp is not None else torch.zeros(bs, n_params).to(z_i)\n                adfdt = adfdt.to(z_i) if adfdt is not None else torch.zeros(bs, 1).to(z_i)\n\n            # Flatten f and adfdz\n            func_eval = func_eval.view(bs, n_dim)\n            adfdz = adfdz.view(bs, n_dim) \n            return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1)\n\n        dLdz = dLdz.view(time_len, bs, n_dim)  # flatten dLdz for convenience\n        with torch.no_grad():\n            ## Create placeholders for output gradients\n            # Prev computed backwards adjoints to be adjusted by direct gradients\n            adj_z = torch.zeros(bs, n_dim).to(dLdz)\n            adj_p = torch.zeros(bs, n_params).to(dLdz)\n            # In contrast to z and p we need to return gradients for all times\n            adj_t = torch.zeros(time_len, bs, 1).to(dLdz)\n\n            for i_t in range(time_len-1, 0, -1):\n                z_i = z[i_t]\n                t_i = t[i_t]\n                f_i = func(z_i, t_i).view(bs, n_dim)\n\n                # Compute direct gradients\n                dLdz_i = dLdz[i_t]\n                dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n\n                # Adjusting adjoints with direct gradients\n                adj_z += dLdz_i\n                adj_t[i_t] = adj_t[i_t] - dLdt_i\n\n                # Pack augmented variable\n                aug_z = torch.cat((z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z), adj_t[i_t]), dim=-1)\n\n                # Solve augmented system backwards\n                aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics)\n\n                # Unpack solved backwards augmented system\n                adj_z[:] = aug_ans[:, n_dim:2*n_dim]\n                adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params]\n                adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:]\n\n                del aug_z, aug_ans\n\n            ## Adjust 0 time adjoint with direct gradients\n            # Compute direct gradients \n            dLdz_0 = dLdz[0]\n            dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0]\n\n            # Adjust adjoints\n            adj_z += dLdz_0\n            adj_t[0] = adj_t[0] - dLdt_0\n        return adj_z.view(bs, *z_shape), adj_t, adj_p, None\n    \nclass NeuralODE(nn.Module):\n    def __init__(self, func):\n        super(NeuralODE, self).__init__()\n        assert isinstance(func, ODEF)\n        self.func = func\n\n    def forward(self, z0, t=torch.Tensor([0., 1.]), return_whole_sequence=False):\n        t = t.to(z0)\n        z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func)\n        if return_whole_sequence:\n            return z\n        else:\n            return z[-1]"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utils",
    "section": "",
    "text": "#hide\nfrom nbdev.showdoc import *\n\n\n#export\nimport numpy as np, pandas as pd\nimport torch\nimport random\n\ndef group_extract(df, group, index='samples', groupby='samples'):\n    return df.groupby(groupby).get_group(group).set_index(index).values\n\ndef sample(data, group, size=(100, ), replace=False, to_torch=False, use_cuda=False):\n    sub = group_extract(data, group)\n    idx = np.arange(sub.shape[0])\n    sampled = sub[np.random.choice(idx, size=size, replace=replace)]\n    if to_torch:\n        sampled = torch.Tensor(sampled).float()\n        if use_cuda:\n            sampled = sampled.cuda()\n    return sampled\n\ndef to_np(data):\n    return data.detach().cpu().numpy()\n\ndef generate_steps(groups):\n    return list(zip(groups[:-1], groups[1:]))\n    \ndef set_seeds(seed:int):\n    torch.manual_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n\ndef config_hold_out(df:pd.DataFrame, hold_out:str='random', hold_one_out:bool=False):\n    DF = None\n    if not hold_one_out: # NOTE: we use all data\n        # NOTE: if hold one out is True and hold_out not 'random', \n        # we train the DAE without this sample\n        DF = df\n        groups = sorted(df.samples.unique())\n    elif hold_one_out is True and hold_out in groups:\n        # create tmp df without all samples\n        df_ho = df.drop(df[df['samples']==hold_out].index, inplace=False)\n        DF = df_ho\n        groups = sorted(df_ho.samples.unique())\n    else:\n        raise ValueError(f'group={hold_out} not in known groups {groups}')\n    return DF, groups\n\nfrom MIOFlow.losses import MMD_loss, OT_loss\ndef config_criterion(criterion_name:str='ot'):\n    _valid_criterion_names = 'ot mmd'.split()\n    if criterion_name == 'mmd':\n        criterion = MMD_loss()\n    elif criterion_name == 'ot':\n        criterion = OT_loss()\n    else:\n        raise NotImplementedError(\n            f'{criterion_name} not implemented.\\n'\n            f'Please use one of {_valid_criterion_names}'\n        )\n    return criterion\n\n\n#export\ndef get_groups_from_df(df, samples_key='samples', samples=None):\n    '''\n    Arguments:\n    ----------\n        df (pd.DataFrame): DataFrame of shape (n_cells, n_genes), where the ordering of \n            the columns `n_genes` corresponds to the columns of `principle_components`.\n            It is assumed that the index of `df` are the cell types (but this need not be the case. \n            See `cell_types`). If there are additional columns (e.g. `samples_key`, `cell_type_key`)\n            should be after the gene columns.\n\n        samples_key (str): The name of the column in the `df` that corresponds to the time\n            samples. Defaults to `\"samples\"`. If `df[samples_key]` throws a `KeyError` \n            either because the `df` doesnt have this column in it or typo, will resort to\n            `samples` to determine this.\n                        \n        samples (np.ndarray | list): List of timepoints where each value corresponds to the \n            timepoint of the same row in `df`. Defaults to `None`.\n    \n    Returns:\n    ---------\n        groups (np.ndarray): List of time groups in order (e.g. `[0, 1, 2, 3, 4, 5, 6, 7]`).\n    '''\n    # Figure out groups from provided samples    \n    try:\n        groups = sorted(df[samples_key].unique())  \n    except KeyError:\n        if samples is not None:\n            groups = sorted(np.unique(samples))  \n        else:\n            raise ValueError(\n                f'DataFrame df has no key {samples_key} and backup list of samples'\n                f' samples is None.'\n            )\n    return groups\n\ndef get_cell_types_from_df(df, cell_type_key=None, cell_types=None):\n    '''\n    Arguments:\n    ----------\n        df (pd.DataFrame): DataFrame of shape (n_cells, n_genes), where the ordering of \n            the columns `n_genes` corresponds to the columns of `principle_components`.\n            It is assumed that the index of `df` are the cell types (but this need not be the case. \n            See `cell_types`). If there are additional columns (e.g. `samples_key`, `cell_type_key`)\n            should be after the gene columns.\n\n        cell_type_key (str): The column name in the provided DataFrame `df` the corresponds to the \n            cell's cell types. Defaults to `None` which assumes the cell type is the index of the \n            `df i.e. `df.index`\n        \n        cell_types (np.ndarray | list): List of cell types to use from the provided DataFrame `df`.\n            Defaults to `None`. If `use_cell_types = True` will attempt to figure this out from\n            `cell_type_key`.\n    \n    Returns:\n    ---------\n        cell_types (np.ndarray): List of cell types.\n    '''\n    if cell_types is None:\n        try:\n            # No column key provided, try to use index\n            if cell_type_key is None:\n                cell_types = sorted(df.index.unique())\n            else:\n                cell_types = sorted(df[cell_type_key].unique())\n        except KeyError:\n            raise KeyError(\n                f'DataFrame df has no key {cell_type_key} and backup list of cell types'\n                ' cell_types is None'\n            )\n    return cell_types\n\n\ndef get_sample_n_from_df(\n    df, n, samples_key='samples', samples=None,    \n    groups=None,\n    drop_index=False\n):\n    '''\n    Arguments:\n    ----------\n        df (pd.DataFrame): DataFrame of shape (n_cells, n_genes), where the ordering of \n            the columns `n_genes` corresponds to the columns of `principle_components`.\n            It is assumed that the index of `df` are the cell types (but this need not be the case. \n            See `cell_types`). If there are additional columns (e.g. `samples_key`, `cell_type_key`)\n            should be after the gene columns.\n\n        samples_key (str): The name of the column in the `df` that corresponds to the time\n            samples. Defaults to `\"samples\"`. If `df[samples_key]` throws a `KeyError` \n            either because the `df` doesnt have this column in it or typo, will resort to\n            `samples` to determine this.\n                        \n        samples (np.ndarray | list): List of timepoints where each value corresponds to the \n            timepoint of the same row in `df`. Defaults to `None`.\n\n        groups (np.ndarray): List of time groups in order (e.g. `[0, 1, 2, 3, 4, 5, 6, 7]`).\n            Defaults to `None`. If `None` will attempt to figure this out from provided\n            `samples_key` or `samples`.\n    \n        drop_index (bool): Whether or not to drop index from `df`. Defaults to `False`.\n\n    Returns:\n    ---------\n        counts_n (pd.DataFrame): subsetted `df` where all rows correspond to `sample==n`.\n    '''\n    if groups is None:\n        groups =  get_groups_from_df(df, samples_key, samples)\n        \n    try:\n        counts_n = df.reset_index(drop=drop_index)[df[samples_key] == groups[n]]\n    except KeyError:\n        if samples is not None:\n            counts_n = df.reset_index(drop=drop_index)[samples == groups[n]]\n        else:\n            raise ValueError(\n                f'DataFrame df has no key {samples_key} and backup list of samples'\n                f' samples is None.'\n            )\n    return counts_n\n\ndef get_times_from_groups(groups, where='start', start=0):\n    '''\n    Arguments:\n    ----------\n        groups (list): the list of the numerical groups in the data, e.g. \n            `[0, 1, 2, 3, 4]`, if the data has five groups.\n        \n        where (str): Choices are `\"start\"`, and `\"end\"`. Defaults to `\"end\"`. Whether or not\n            to start the trajectories at `t_0` (`\"start\"`) or `t_n` (`\"end\"`). \n    \n        start (int): Defaults to `0`. Where in `generate_tjnet_trajectories` the trajectories started.\n            This is used if attempting to generate outside of `t0`. Note this works relative to `where`.\n            E.g. if `where=\"end\"` and `start=0` then this is the same as `groups[-1]`.\n\n    Returns:\n        times (list): The `groups` starting at `start` working from `end`.\n    '''\n    _valid_where = 'start end'.split()\n    if where not in _valid_where:\n        raise ValueError(f'{where} not known. Should be one of {_valid_where}')\n\n    times = groups\n    if where == 'end':\n        times = times[::-1]\n    times = times[start:]\n    return times"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MIOFlow",
    "section": "",
    "text": "To get all the pagackes required, run the following command:\n$ conda env create -f environment.yml\nThis will create a new conda environment sklab-mioflow, which can be activated via:\nconda activate sklab-mioflow\n\n\n\n\nFor greater detail see the official docs for nb_conda_kernels. In short, install nb_conda_kernels in the environment from which you launch JupyterLab / Jupyter Notebooks from (e.g.Â base) via:\n$ conda install -n <notebook_env> nb_conda_kernels\nto add a new or exist conda environment to Jupyter simply install ipykernel into that conda environment e.g.\n$ conda install -n <python_env> ipykernel\n\n\n\nadd to your Jupyter Notebook kernels via\n$ python -m ipykernel install --user --name sklab-mioflow\nIt can be removed via:\n$ jupyter kernelspec uninstall sklab-mioflow\n\n\n\nkernels recognized by conda\n$ python -m nb_conda_kernels list\ncheck which kernels are discovered by Jupyter:\n$ jupyter kernelspec list"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "MIOFlow",
    "section": "Install",
    "text": "Install\n\nFor developers and internal use:\ncd path/to/this/repository\npip install -e MIOFlow\n\n\nFor production use:\npip install MIOFlow"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "MIOFlow",
    "section": "How to use",
    "text": "How to use\nThis repository consists of our python library MIOFlow as well as a directory of scripts for running and using it.\n\nScripts\nTo recreate our results with MMD loss and density regulariazation you can run the following command:\npython scripts/run.py -d petals -c mmd -n petal-mmd\nThis will generate the directory results/petals-mmd and save everything there.\nFor a full list of parameters try running:\npython scripts/run.py --help\n\n\nPython Package\nOne could simply import everything and use it piecemeal:\n\nfrom MIOFlow.ode import *\nfrom MIOFlow.losses import *\nfrom MIOFlow.utils import *\nfrom MIOFlow.models import *\nfrom MIOFlow.plots import *\nfrom MIOFlow.train import *\nfrom MIOFlow.constants import *\nfrom MIOFlow.datasets import *\nfrom MIOFlow.exp import *\nfrom MIOFlow.geo import *\nfrom MIOFlow.eval import *\n\n\n\nTutorials\nOne can also consult or modify the tutorial notebooks for their uses: - EB Bodies tutorial - Dyngen tutorial - Petals tutorial"
  },
  {
    "objectID": "train.html",
    "href": "train.html",
    "title": "Train",
    "section": "",
    "text": "#hide\nfrom nbdev.showdoc import *\n\n\n#export\nimport os, sys, json, math, itertools\nimport pandas as pd, numpy as np\nimport warnings\n\n# from tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\nimport torch\n\nfrom MIOFlow.utils import sample, generate_steps\nfrom MIOFlow.losses import MMD_loss, OT_loss, Density_loss, Local_density_loss\n\ndef train(\n    model, df, groups, optimizer, n_batches=20, \n    criterion=MMD_loss(),\n    use_cuda=False,\n\n    sample_size=(100, ),\n    sample_with_replacement=False,\n\n    local_loss=True,\n    global_loss=False,\n\n    hold_one_out=False,\n    hold_out='random',\n    apply_losses_in_time=True,\n\n    top_k = 5,\n    hinge_value = 0.01,\n    use_density_loss=True,\n    # use_local_density=False,\n\n    lambda_density = 1.0,\n\n    autoencoder=None, \n    use_emb=True,\n    use_gae=False,\n\n    use_gaussian:bool=True, \n    add_noise:bool=False, \n    noise_scale:float=0.1,\n    \n    logger=None,\n\n    use_penalty=False,\n    lambda_energy=1.0,\n\n    reverse:bool = False\n):\n\n    '''\n    MIOFlow training loop\n    \n    Notes:\n        - The argument `model` must have a method `forward` that accepts two arguments\n            in its function signature:\n                ```python\n                model.forward(x, t)\n                ```\n            where, `x` is the input tensor and `t` is a `torch.Tensor` of time points (float).\n        - The training loop is divided in two parts; local (predict t+1 from t), and global (predict the entire trajectory).\n                        \n    Arguments:\n        model (nn.Module): the initialized pytorch ODE model.\n        \n        df (pd.DataFrame): the DataFrame from which to extract batch data.\n        \n        groups (list): the list of the numerical groups in the data, e.g. \n            `[1.0, 2.0, 3.0, 4.0, 5.0]`, if the data has five groups.\n    \n        optimizer (torch.optim): an optimizer initilized with the model's parameters.\n        \n        n_batches (int): Default to '20', the number of batches from which to randomly sample each consecutive pair\n            of groups.\n            \n        criterion (Callable | nn.Loss): a loss function.\n        \n        use_cuda (bool): Defaults to `False`. Whether or not to send the model and data to cuda. \n\n        sample_size (tuple): Defaults to `(100, )`\n\n        sample_with_replacement (bool): Defaults to `False`. Whether or not to sample data points with replacement.\n        \n        local_loss (bool): Defaults to `True`. Whether or not to use a local loss in the model.\n            See notes for more detail.\n            \n        global_loss (bool): Defaults to `False`. Whether or not to use a global loss in the model.\n        \n        hold_one_out (bool): Defaults to `False`. Whether or not to randomly hold one time pair\n            e.g. t_1 to t_2 out when computing the global loss.\n\n        hold_out (str | int): Defaults to `\"random\"`. Which time point to hold out when calculating the\n            global loss.\n            \n        apply_losses_in_time (bool): Defaults to `True`. Applies the losses and does back propegation\n            as soon as a loss is calculated. See notes for more detail.\n\n        top_k (int): Default to '5'. The k for the k-NN used in the density loss.\n\n        hinge_value (float): Defaults to `0.01`. The hinge value for density loss.\n\n        use_density_loss (bool): Defaults to `True`. Whether or not to add density regularization.\n\n        lambda_density (float): Defaults to `1.0`. The weight for density loss.\n\n        autoencoder (NoneType|nn.Module): Default to 'None'. The full geodesic Autoencoder.\n\n        use_emb (bool): Defaults to `True`. Whether or not to use the embedding model.\n        \n        use_gae (bool): Defaults to `False`. Whether or not to use the full Geodesic AutoEncoder.\n\n        use_gaussian (bool): Defaults to `True`. Whether to use random or gaussian noise.\n\n        add_noise (bool): Defaults to `False`. Whether or not to add noise.\n\n        noise_scale (float): Defaults to `0.30`. How much to scale the noise by.\n        \n        logger (NoneType|Logger): Default to 'None'. The logger to record information.\n\n        use_penalty (bool): Defaults to `False`. Whether or not to use $L_e$ during training (norm of the derivative).\n        \n        lambda_energy (float): Default to '1.0'. The weight of the energy penalty.\n\n        reverse (bool): Whether to train time backwards.\n    '''\n    if autoencoder is None and (use_emb or use_gae):\n        use_emb = False\n        use_gae = False\n        warnings.warn('\\'autoencoder\\' is \\'None\\', but \\'use_emb\\' or \\'use_gae\\' is True, both will be set to False.')\n\n    noise_fn = torch.randn if use_gaussian else torch.rand\n    def noise(data):\n        return noise_fn(*data.shape).cuda() if use_cuda else noise_fn(*data.shape)\n    # Create the indicies for the steps that should be used\n    steps = generate_steps(groups)\n\n    if reverse:\n        groups = groups[::-1]\n        steps = generate_steps(groups)\n\n    \n    # Storage variables for losses\n    batch_losses = []\n    globe_losses = []\n    if hold_one_out and hold_out in groups:\n        groups_ho = [g for g in groups if g != hold_out]\n        local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups_ho) if hold_out not in [t0, t1]}\n    else:\n        local_losses = {f'{t0}:{t1}':[] for (t0, t1) in steps}\n        \n    density_fn = Density_loss(hinge_value) # if not use_local_density else Local_density_loss()\n\n    # Send model to cuda and specify it as training mode\n    if use_cuda:\n        model = model.cuda()\n    \n    model.train()\n    \n    for batch in tqdm(range(n_batches)):\n        \n        # apply local loss\n        if local_loss and not global_loss:\n            # for storing the local loss with calling `.item()` so `loss.backward()` can still be used\n            batch_loss = []\n            if hold_one_out:\n                groups = [g for g in groups if g != hold_out] # TODO: Currently does not work if hold_out='random'. Do to_ignore before. \n                steps = generate_steps(groups)\n            for step_idx, (t0, t1) in enumerate(steps):  \n                if hold_out in [t0, t1] and hold_one_out: # TODO: This `if` can be deleted since the groups does not include the ho timepoint anymore\n                    continue                              # i.e. it is always False. \n                optimizer.zero_grad()\n                \n                #sampling, predicting, and evaluating the loss.\n                # sample data\n                data_t0 = sample(df, t0, size=sample_size, replace=sample_with_replacement, to_torch=True, use_cuda=use_cuda)\n                data_t1 = sample(df, t1, size=sample_size, replace=sample_with_replacement, to_torch=True, use_cuda=use_cuda)\n                time = torch.Tensor([t0, t1]).cuda() if use_cuda else torch.Tensor([t0, t1])\n\n                if add_noise:\n                    data_t0 += noise(data_t0) * noise_scale\n                    data_t1 += noise(data_t1) * noise_scale\n                if autoencoder is not None and use_gae:\n                    data_t0 = autoencoder.encoder(data_t0)\n                    data_t1 = autoencoder.encoder(data_t1)\n                # prediction\n                data_tp = model(data_t0, time)\n\n                if autoencoder is not None and use_emb:        \n                    data_tp, data_t1 = autoencoder.encoder(data_tp), autoencoder.encoder(data_t1)\n                # loss between prediction and sample t1\n                loss = criterion(data_tp, data_t1)\n\n                if use_density_loss:                \n                    density_loss = density_fn(data_tp, data_t1, top_k=top_k)\n                    loss += lambda_density * density_loss\n\n                if use_penalty:\n                    penalty = sum(model.norm)\n                    loss += lambda_energy * penalty\n\n                # apply local loss as we calculate it\n                if apply_losses_in_time and local_loss:\n                    loss.backward()\n                    optimizer.step()\n                    model.norm=[]\n                # save loss in storage variables \n                local_losses[f'{t0}:{t1}'].append(loss.item())\n                batch_loss.append(loss)\n        \n        \n            # convert the local losses into a tensor of len(steps)\n            batch_loss = torch.Tensor(batch_loss).float()\n            if use_cuda:\n                batch_loss = batch_loss.cuda()\n            \n            if not apply_losses_in_time:\n                batch_loss.backward()\n                optimizer.step()\n\n            # store average / sum of local losses for training\n            ave_local_loss = torch.mean(batch_loss)\n            sum_local_loss = torch.sum(batch_loss)            \n            batch_losses.append(ave_local_loss.item())\n        \n        # apply global loss\n        elif global_loss and not local_loss:\n            optimizer.zero_grad()\n            #sampling, predicting, and evaluating the loss.\n            # sample data\n            data_ti = [\n                sample(\n                    df, group, size=sample_size, replace=sample_with_replacement, \n                    to_torch=True, use_cuda=use_cuda\n                )\n                for group in groups\n            ]\n            time = torch.Tensor(groups).cuda() if use_cuda else torch.Tensor(groups)\n\n            if add_noise:\n                data_ti = [\n                    data + noise(data) * noise_scale for data in data_ti\n                ]\n            if autoencoder is not None and use_gae:\n                data_ti = [autoencoder.encoder(data) for data in data_ti]\n            # prediction\n            data_tp = model(data_ti[0], time, return_whole_sequence=True)\n            if autoencoder is not None and use_emb:        \n                data_tp = [autoencoder.encoder(data) for data in data_tp]\n                data_ti = [autoencoder.encoder(data) for data in data_ti]\n\n            #ignoring one time point\n            to_ignore = None #TODO: This assignment of `to_ingnore`, could be moved at the beginning of the function. \n            if hold_one_out and hold_out == 'random':\n                to_ignore = np.random.choice(groups)\n            elif hold_one_out and hold_out in groups:\n                to_ignore = hold_out\n            elif hold_one_out:\n                raise ValueError('Unknown group to hold out')\n            else:\n                pass\n\n            loss = sum([\n                criterion(data_tp[i], data_ti[i]) \n                for i in range(1, len(groups))\n                if groups[i] != to_ignore\n            ])\n\n            if use_density_loss:                \n                density_loss = density_fn(data_tp, data_ti, groups, to_ignore, top_k)\n                loss += lambda_density * density_loss\n\n            if use_penalty:\n                penalty = sum([model.norm[-(i+1)] for i in range(1, len(groups))\n                    if groups[i] != to_ignore])\n                loss += lambda_energy * penalty\n                                       \n            loss.backward()\n            optimizer.step()\n            model.norm=[]\n\n            globe_losses.append(loss.item())\n        elif local_loss and global_loss:\n            # NOTE: weighted local / global loss has been removed to improve runtime\n            raise NotImplementedError()\n        else:\n            raise ValueError('A form of loss must be specified.')\n                     \n    print_loss = globe_losses if global_loss else batch_losses \n    if logger is None:      \n        tqdm.write(f'Train loss: {np.round(np.mean(print_loss), 5)}')\n    else:\n        logger.info(f'Train loss: {np.round(np.mean(print_loss), 5)}')\n    return local_losses, batch_losses, globe_losses\n\n\n#export\nfrom MIOFlow.utils import generate_steps\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm\nimport numpy as np\n\ndef train_ae(\n    model, df, groups, optimizer,\n    n_epochs=60, criterion=nn.MSELoss(), dist=None, recon = True,\n    use_cuda=False, sample_size=(100, ),\n    sample_with_replacement=False,\n    noise_min_scale=0.09,\n    noise_max_scale=0.15,\n    hold_one_out:bool=False,\n    hold_out='random'\n    \n):\n    \"\"\"\n    Geodesic Autoencoder training loop.\n    \n    Notes:\n        - We can train only the encoder the fit the geodesic distance (recon=False), or the full geodesic Autoencoder (recon=True),\n            i.e. matching the distance and reconstruction of the inputs.\n            \n    Arguments:\n    \n        model (nn.Module): the initialized pytorch Geodesic Autoencoder model.\n\n        df (pd.DataFrame): the DataFrame from which to extract batch data.\n        \n        groups (list): the list of the numerical groups in the data, e.g. \n            `[1.0, 2.0, 3.0, 4.0, 5.0]`, if the data has five groups.\n\n        optimizer (torch.optim): an optimizer initilized with the model's parameters.\n\n        n_epochs (int): Default to '60'. The number of training epochs.\n\n        criterion (torch.nn). Default to 'nn.MSELoss()'. The criterion to minimize. \n\n        dist (NoneType|Class). Default to 'None'. The distance Class with a 'fit(X)' method for a dataset 'X'. Computes the pairwise distances in 'X'.\n\n        recon (bool): Default to 'True'. Whether or not the apply the reconstruction loss. \n        \n        use_cuda (bool): Defaults to `False`. Whether or not to send the model and data to cuda. \n        \n        sample_size (tuple): Defaults to `(100, )`.\n        \n        sample_with_replacement (bool): Defaults to `False`. Whether or not to sample data points with replacement.\n        \n        noise_min_scale (float): Default to '0.0'. The minimum noise scale. \n        \n        noise_max_scale (float): Default to '1.0'. The maximum noise scale. The true scale is sampled between these two bounds for each epoch. \n        \n        hold_one_out (bool): Default to False, whether or not to ignore a timepoint during training.\n        \n        hold_out (str|int): Default to 'random', the timepoint to hold out, either a specific element of 'groups' or a random one. \n    \n    \"\"\"\n    steps = generate_steps(groups)\n    losses = []\n\n    model.train()\n    for epoch in tqdm(range(n_epochs)):\n        \n        # ignoring one time point\n        to_ignore = None\n        if hold_one_out and hold_out == 'random':\n            to_ignore = np.random.choice(groups)\n        elif hold_one_out and hold_out in groups:\n            to_ignore = hold_out\n        elif hold_one_out:\n            raise ValueError('Unknown group to hold out')\n        else:\n            pass\n        \n        # Training\n        optimizer.zero_grad()\n        noise_scale = torch.FloatTensor(1).uniform_(noise_min_scale, noise_max_scale)\n        data_ti = torch.vstack([sample(df, group, size=sample_size, replace=sample_with_replacement, to_torch=True, use_cuda=use_cuda) for group in groups if group != to_ignore])\n        noise = (noise_scale*torch.randn(data_ti.size())).cuda() if use_cuda else noise_scale*torch.randn(data_ti.size())\n        \n        encode_dt = model.encoder(data_ti + noise)\n        recon_dt = model.decoder(encode_dt) if recon else None\n        \n        if recon:\n            loss_recon = criterion(recon_dt,data_ti)\n            loss = loss_recon\n            \n            if epoch%50==0:\n                tqdm.write(f'Train loss recon: {np.round(np.mean(loss_recon.item()), 5)}')\n        \n        if dist is not None:\n            dist_geo = dist.fit(data_ti.cpu().numpy())\n            dist_geo = torch.from_numpy(dist_geo).float().cuda() if use_cuda else torch.from_numpy(dist_geo).float()\n            dist_emb = torch.cdist(encode_dt,encode_dt)**2\n            loss_dist = criterion(dist_emb,dist_geo)\n            loss = loss_recon + loss_dist if recon else loss_dist\n            \n            if epoch%50==0:\n                tqdm.write(f'Train loss dist: {np.round(np.mean(loss_dist.item()), 5)}')\n                \n        loss.backward()\n        optimizer.step()\n        \n        losses.append(loss.item())\n    return losses\n\n\n#export\nfrom MIOFlow.plots import plot_comparision, plot_losses\nfrom MIOFlow.eval import generate_plot_data\n\ndef training_regimen(\n    n_local_epochs, n_epochs, n_post_local_epochs,\n    exp_dir, \n\n    # BEGIN: train params\n    model, df, groups, optimizer, n_batches=20, \n    criterion=MMD_loss(), use_cuda=False,\n\n\n    hold_one_out=False, hold_out='random', \n    hinge_value=0.01, use_density_loss=True, \n\n    top_k = 5, lambda_density = 1.0, \n    autoencoder=None, use_emb=True, use_gae=False, \n    sample_size=(100, ), \n    sample_with_replacement=False, \n    logger=None, \n    add_noise=False, noise_scale=0.1, use_gaussian=True,  \n    use_penalty=False, lambda_energy=1.0,\n    # END: train params\n\n\n\n    steps=None, plot_every=None,\n    n_points=100, n_trajectories=100, n_bins=100, \n    local_losses=None, batch_losses=None, globe_losses=None,\n    reverse_schema=True, reverse_n=4\n):\n    recon = use_gae and not use_emb\n    if steps is None:\n        steps = generate_steps(groups)\n        \n    if local_losses is None:\n        if hold_one_out and hold_out in groups:\n            groups_ho = [g for g in groups if g != hold_out]\n            local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups_ho) if hold_out not in [t0, t1]}\n            if reverse_schema:\n                local_losses = {\n                    **local_losses, \n                    **{f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups_ho[::-1]) if hold_out not in [t0, t1]}\n                }\n        else:\n            local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups)}\n            if reverse_schema:\n                local_losses = {\n                    **local_losses, \n                    **{f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups[::-1])}\n                }\n    if batch_losses is None:\n        batch_losses = []\n    if globe_losses is None:\n        globe_losses = []\n    \n    reverse = False\n    for epoch in tqdm(range(n_local_epochs), desc='Pretraining Epoch'):\n        reverse = True if reverse_schema and epoch % reverse_n == 0 else False\n\n        l_loss, b_loss, g_loss = train(\n            model, df, groups, optimizer, n_batches, \n            criterion = criterion, use_cuda = use_cuda,\n            local_loss=True, global_loss=False, apply_losses_in_time=True,\n            hold_one_out=hold_one_out, hold_out=hold_out, \n            hinge_value=hinge_value,\n            use_density_loss = use_density_loss,    \n            top_k = top_k, lambda_density = lambda_density, \n            autoencoder = autoencoder, use_emb = use_emb, use_gae = use_gae, sample_size=sample_size, \n            sample_with_replacement=sample_with_replacement, logger=logger,\n            add_noise=add_noise, noise_scale=noise_scale, use_gaussian=use_gaussian, \n            use_penalty=use_penalty, lambda_energy=lambda_energy, reverse=reverse\n        )\n        for k, v in l_loss.items():  \n            local_losses[k].extend(v)\n        batch_losses.extend(b_loss)\n        globe_losses.extend(g_loss)\n        if plot_every is not None and epoch % plot_every == 0:\n            generated, trajectories = generate_plot_data(\n                model, df, n_points, n_trajectories, n_bins, \n                sample_with_replacement=sample_with_replacement, use_cuda=use_cuda, \n                samples_key='samples', logger=logger,\n                autoencoder=autoencoder, recon=recon\n            )\n            plot_comparision(\n                df, generated, trajectories,\n                palette = 'viridis', df_time_key='samples',\n                save=True, path=exp_dir, \n                file=f'2d_comparision_local_{epoch}.png',\n                x='d1', y='d2', z='d3', is_3d=False\n            )\n\n    for epoch in tqdm(range(n_epochs), desc='Epoch'):\n        reverse = True if reverse_schema and epoch % reverse_n == 0 else False\n        l_loss, b_loss, g_loss = train(\n            model, df, groups, optimizer, n_batches, \n            criterion = criterion, use_cuda = use_cuda,\n            local_loss=False, global_loss=True, apply_losses_in_time=True,\n            hold_one_out=hold_one_out, hold_out=hold_out, \n            hinge_value=hinge_value,\n            use_density_loss = use_density_loss,       \n            top_k = top_k, lambda_density = lambda_density, \n            autoencoder = autoencoder, use_emb = use_emb, use_gae = use_gae, sample_size=sample_size, \n            sample_with_replacement=sample_with_replacement, logger=logger, \n            add_noise=add_noise, noise_scale=noise_scale, use_gaussian=use_gaussian,\n            use_penalty=use_penalty, lambda_energy=lambda_energy, reverse=reverse\n        )\n        for k, v in l_loss.items():  \n            local_losses[k].extend(v)\n        batch_losses.extend(b_loss)\n        globe_losses.extend(g_loss)\n        if plot_every is not None and epoch % plot_every == 0:\n            generated, trajectories = generate_plot_data(\n                model, df, n_points, n_trajectories, n_bins, \n                sample_with_replacement=sample_with_replacement, use_cuda=use_cuda, \n                samples_key='samples', logger=logger,\n                autoencoder=autoencoder, recon=recon\n            )\n            plot_comparision(\n                df, generated, trajectories,\n                palette = 'viridis', df_time_key='samples',\n                save=True, path=exp_dir, \n                file=f'2d_comparision_local_{n_local_epochs}_global_{epoch}.png',\n                x='d1', y='d2', z='d3', is_3d=False\n            )\n        \n    for epoch in tqdm(range(n_post_local_epochs), desc='Posttraining Epoch'):\n        reverse = True if reverse_schema and epoch % reverse_n == 0 else False\n\n        l_loss, b_loss, g_loss = train(\n            model, df, groups, optimizer, n_batches, \n            criterion = criterion, use_cuda = use_cuda,\n            local_loss=True, global_loss=False, apply_losses_in_time=True,\n            hold_one_out=hold_one_out, hold_out=hold_out, \n            hinge_value=hinge_value,\n            use_density_loss = use_density_loss,       \n            top_k = top_k, lambda_density = lambda_density,  \n            autoencoder = autoencoder, use_emb = use_emb, use_gae = use_gae, sample_size=sample_size, \n            sample_with_replacement=sample_with_replacement, logger=logger, \n            add_noise=add_noise, noise_scale=noise_scale, use_gaussian=use_gaussian,\n            use_penalty=use_penalty, lambda_energy=lambda_energy, reverse=reverse\n        )\n        for k, v in l_loss.items():  \n            local_losses[k].extend(v)\n        batch_losses.extend(b_loss)\n        globe_losses.extend(g_loss)\n        if plot_every is not None and epoch % plot_every == 0:\n            generated, trajectories = generate_plot_data(\n                model, df, n_points, n_trajectories, n_bins, \n                sample_with_replacement=sample_with_replacement, use_cuda=use_cuda, \n                samples_key='samples', logger=logger,\n                autoencoder=autoencoder, recon=recon\n            )\n            plot_comparision(\n                df, generated, trajectories,\n                palette = 'viridis', df_time_key='samples',\n                save=True, path=exp_dir, \n                file=f'2d_comparision_local_{n_local_epochs}_global_{n_epochs}_post_{epoch}.png',\n                x='d1', y='d2', z='d3', is_3d=False\n            )\n\n    if reverse_schema:\n        _temp = {}\n        if hold_one_out:\n            for (t0, t1) in generate_steps([g for g in groups if g != hold_out]):\n                a = f'{t0}:{t1}'\n                b = f'{t1}:{t0}'\n                _temp[a] = []\n                for i, value in enumerate(local_losses[a]):\n\n                    if i % reverse_n == 0:\n                        _temp[a].append(local_losses[b].pop(0))\n                        _temp[a].append(value)\n                    else:\n                        _temp[a].append(value)\n            local_losses = _temp\n        else:\n            for (t0, t1) in generate_steps(groups):\n                a = f'{t0}:{t1}'\n                b = f'{t1}:{t0}'\n                _temp[a] = []\n                for i, value in enumerate(local_losses[a]):\n\n                    if i % reverse_n == 0:\n                        _temp[a].append(local_losses[b].pop(0))\n                        _temp[a].append(value)\n                    else:\n                        _temp[a].append(value)\n            local_losses = _temp\n\n\n\n    if plot_every is not None:\n        plot_losses(\n            local_losses, batch_losses, globe_losses, \n            save=True, path=exp_dir, \n            file=f'losses_l{n_local_epochs}_e{n_epochs}_ple{n_post_local_epochs}.png'\n        )\n\n    return local_losses, batch_losses, globe_losses"
  },
  {
    "objectID": "losses.html",
    "href": "losses.html",
    "title": "Losses",
    "section": "",
    "text": "MMD_loss\n\n MMD_loss (kernel_mul=2.0, kernel_num=5)\n\nhttps://github.com/ZongxianLee/MMD_Loss.Pytorch/blob/master/mmd_loss.py\n\n\n\nOT_loss\n\n OT_loss (which='emd', use_cuda=True)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nDensity_loss\n\n Density_loss (hinge_value=0.01)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nLocal_density_loss\n\n Local_density_loss ()\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool"
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "Models",
    "section": "",
    "text": "#hide\nfrom nbdev.showdoc import *\n\n\n#export\nimport itertools\nfrom torch.nn  import functional as F \nimport torch.nn as nn\nimport torch\nclass ToyODE(nn.Module):\n    \"\"\" \n    ODE derivative network\n    \n    feature_dims (int) default '5': dimension of the inputs, either in ambient space or embedded space.\n    layer (list of int) defaulf ''[64]'': the hidden layers of the network.\n    activation (torch.nn) default '\"ReLU\"': activation function applied in between layers.\n    scales (NoneType|list of float) default 'None': the initial scale for the noise in the trajectories. One scale per bin, add more if using an adaptative ODE solver.\n    n_aug (int) default '1': number of added dimensions to the input of the network. Total dimensions are features_dim + 1 (time) + n_aug. \n    \n    Method\n    forward (Callable)\n        forward pass of the ODE derivative network.\n        Parameters:\n        t (torch.tensor): time of the evaluation.\n        x (torch.tensor): position of the evalutation.\n        Return:\n        derivative at time t and position x.   \n    \"\"\"\n    def __init__(\n        self, \n        feature_dims=5,\n        layers=[64],\n        activation='ReLU',\n        scales=None,\n        n_aug=2\n    ):\n        super(ToyODE, self).__init__()\n        steps = [feature_dims+1+n_aug, *layers, feature_dims]\n        pairs = zip(steps, steps[1:])\n\n        chain = list(itertools.chain(*list(zip(\n            map(lambda e: nn.Linear(*e), pairs), \n            itertools.repeat(getattr(nn, activation)())\n        ))))[:-1]\n\n        self.chain = chain\n        self.seq = (nn.Sequential(*chain))\n        \n        self.alpha = nn.Parameter(torch.tensor(scales, requires_grad=True).float()) if scales is not None else None\n        self.n_aug = n_aug        \n        \n    def forward(self, t, x): #NOTE the forward pass when we use torchdiffeq must be forward(self,t,x)\n        zero = torch.tensor([0]).cuda() if x.is_cuda else torch.tensor([0])\n        zeros = zero.repeat(x.size()[0],self.n_aug)\n        time = t.repeat(x.size()[0],1)\n        aug = torch.cat((x,time,zeros),dim=1)\n        x = self.seq(aug)\n        if self.alpha is not None:\n            z = torch.randn(x.size(),requires_grad=False).cuda() if x.is_cuda else torch.randn(x.size(),requires_grad=False)\n        dxdt = x + z*self.alpha[int(t-1)] if self.alpha is not None else x\n        return dxdt\n\n\n#export\ndef make_model(\n    feature_dims=5,\n    layers=[64],\n    output_dims=5,\n    activation='ReLU',\n    which='ode',\n    method='rk4',\n    rtol=None,\n    atol=None,\n    scales=None,\n    n_aug=2,\n    noise_type='diagonal', sde_type='ito',\n    use_norm=False,\n    use_cuda=False,\n    in_features=2, out_features=2, gunc=None\n):\n    \"\"\"\n    Creates the 'ode' model or 'sde' model or the Geodesic Autoencoder. \n    See the parameters of the respective classes.\n    \"\"\"\n    if which == 'ode':\n        ode = ToyODE(feature_dims, layers, activation,scales,n_aug)\n        model = ToyModel(ode,method,rtol, atol, use_norm=use_norm)\n    elif which == 'sde':\n        ode = ToyODE(feature_dims, layers, activation,scales,n_aug)\n        model = ToySDEModel(\n            ode, method, noise_type, sde_type,\n            in_features=in_features, out_features=out_features, gunc=gunc\n            \n        )\n    else:\n        model = ToyGeo(feature_dims, layers, output_dims, activation)\n    if use_cuda:\n        model.cuda()\n    return model\n\n\n#export\nimport itertools\nimport torch.nn as nn\nfrom torch.nn  import functional as F \n\nclass Autoencoder(nn.Module):\n    \"\"\" \n    Geodesic Autoencoder\n    \n    encoder_layers (list of int) default '[100, 100, 20]': encoder_layers[0] is the feature dimension, and encoder_layers[-1] the embedded dimension.\n    decoder_layers (list of int) defaulf '[20, 100, 100]': decoder_layers[0] is the embbeded dim and decoder_layers[-1] the feature dim.\n    activation (torch.nn) default '\"Tanh\"': activation function applied in between layers.\n    use_cuda (bool) default to False: Whether to use GPU or CPU.\n    \n    Method\n    encode\n        forward pass of the encoder\n        x (torch.tensor): observations\n        Return:\n        the encoded observations\n    decode\n        forward pass of the decoder\n        z (torch.tensor): embedded observations\n        Return:\n        the decoded observations\n    forward (Callable):\n        full forward pass, encoder and decoder\n        x (torch.tensor): observations\n        Return:\n        denoised observations\n    \"\"\"\n\n    def __init__(\n        self,\n        encoder_layers = [100, 100, 20],\n        decoder_layers = [20, 100, 100],\n        activation = 'Tanh',\n        use_cuda = False\n    ):        \n        super(Autoencoder, self).__init__()\n        if decoder_layers is None:\n            decoder_layers = [*encoder_layers[::-1]]\n        device = 'cuda' if use_cuda else 'cpu'\n        \n        encoder_shapes = list(zip(encoder_layers, encoder_layers[1:]))\n        decoder_shapes = list(zip(decoder_layers, decoder_layers[1:]))\n        \n        encoder_linear = list(map(lambda a: nn.Linear(*a), encoder_shapes))\n        decoder_linear = list(map(lambda a: nn.Linear(*a), decoder_shapes))\n        \n        encoder_riffle = list(itertools.chain(*zip(encoder_linear, itertools.repeat(getattr(nn, activation)()))))[:-1]\n        encoder = nn.Sequential(*encoder_riffle).to(device)\n        \n        decoder_riffle = list(itertools.chain(*zip(decoder_linear, itertools.repeat(getattr(nn, activation)()))))[:-1]\n\n        decoder = nn.Sequential(*decoder_riffle).to(device)\n        self.encoder = encoder\n        self.decoder = decoder\n\n        \n    \n    def encode(self, x):\n        return self.encoder(x)\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        z = self.encoder(x)\n        return self.decoder(z)\n\n: \n\n\n\n#export\n\nfrom torchdiffeq import odeint_adjoint as odeint\nimport os, math, numpy as np\nimport torch\nimport torch.nn as nn\nclass ToyModel(nn.Module):\n    \"\"\" \n    Neural ODE\n        func (nn.Module): The network modeling the derivative.\n        method (str) defaulf '\"rk4\"': any methods from torchdiffeq.\n        rtol (NoneType | float): the relative tolerance of the ODE solver.\n        atol (NoneType | float): the absolute tolerance. of the ODE solver.\n        use_norm (bool): if True keeps the norm of func.\n        norm (list of torch.tensor): the norm of the derivative.\n        \n        Method\n        forward (Callable)\n            x (torch.tensor): the initial sample\n            t (torch.tensor) time points where we suppose x is from t[0]\n            return the last sample or the whole seq.      \n    \"\"\"\n    \n    def __init__(self, func, method='rk4', rtol=None, atol=None, use_norm=False):\n        super(ToyModel, self).__init__()        \n        self.func = func\n        self.method = method\n        self.rtol=rtol\n        self.atol=atol\n        self.use_norm = use_norm\n        self.norm=[]\n\n    def forward(self, x, t, return_whole_sequence=False):\n\n        if self.use_norm:\n            for time in t: \n                self.norm.append(torch.linalg.norm(self.func(time,x)).pow(2))\n        if self.atol is None and self.rtol is None:\n            x = odeint(self.func,x ,t, method=self.method)\n        elif self.atol is not None and self.rtol is None:\n            x = odeint(self.func,x ,t, method=self.method, atol=self.atol)\n        elif self.atol is None and self.rtol is not None:\n            x = odeint(self.func,x ,t, method=self.method, rtol=self.rtol)\n        else: \n            x = odeint(self.func,x ,t, method=self.method, atol=self.atol, rtol=self.rtol)          \n       \n        x = x[-1] if not return_whole_sequence else x\n        return x\n\n\n#export\n\nfrom torchdiffeq import odeint_adjoint as odeint\nimport os, math, numpy as np\nimport torch\nimport torch.nn as nn\nimport torchsde\n\nclass ToySDEModel(nn.Module):\n    \"\"\" \n    Neural SDE model\n        func (nn.Module): drift term.\n        genc (nn.Module): diffusion term.\n        method (str): method of the SDE solver.\n        \n        Method\n        forward (Callable)\n            x (torch.tensor): the initial sample\n            t (torch.tensor) time points where we suppose x is from t[0]\n            return the last sample or the whole seq.  \n    \"\"\"\n    \n    def __init__(self, func, method='euler', noise_type='diagonal', sde_type='ito', \n    in_features=2, out_features=2, gunc=None, dt=0.1):\n        super(ToySDEModel, self).__init__()        \n        self.func = func\n        self.method = method\n        self.noise_type = noise_type\n        self.sde_type = sde_type\n        if gunc is None:\n            self._gunc_args = 'y'\n            self.gunc = nn.Linear(in_features, out_features)\n        else:\n            self._gunc_args = 't,y'\n            self.gunc = gunc\n\n        self.dt = dt\n        \n    def f(self, t, y):\n        return self.func(t, y)\n\n    def g(self, t, y):\n        return self.gunc(t, y) if self._gunc_args == 't,y' else self.gunc(y)\n        return 0.3 * torch.sigmoid(torch.cos(t) * torch.exp(-y))\n\n    def forward(self, x, t, return_whole_sequence=False, dt=None):\n        dt = self.dt if self.dt is not None else 0.1 if dt is None else dt        \n        x = torchsde.sdeint(self, x, t, method=self.method, dt=dt)\n       \n        x = x[-1] if not return_whole_sequence else x\n        return x"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "MIOFlow",
    "section": "",
    "text": "Before anything else, please install the git hooks that run automatic scripts during each commit and merge to strip the notebooks of superfluous metadata (and avoid merge conflicts). After cloning the repository, run the following command inside it:\nnbdev_install_git_hooks\n\n\n\n\nEnsure the bug was not already reported by searching on GitHub under Issues.\nIf youâ€™re unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behavior that is not occurring.\nBe sure to add the complete error messages.\n\n\n\n\nOpen a new GitHub pull request with the patch.\nEnsure that your PR includes a test that fails without your patch, and pass with it.\nEnsure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable.\n\n\n\n\n\n\nKeep each PR focused. While itâ€™s more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\nDo not mix style changes/fixes with â€œfunctionalâ€ changes. Itâ€™s very difficult to review such PRs and it most likely get rejected.\nDo not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\nDo not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\nIf, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and wonâ€™t need to review the whole PR again. In the exception case where you realize itâ€™ll take many many commits to complete the requests, then itâ€™s probably best to close the PR, do the work and then submit it again. Use common sense where youâ€™d choose one way over another.\n\n\n\n\n\nDocs are automatically created from the notebooks in the nbs folder."
  }
]