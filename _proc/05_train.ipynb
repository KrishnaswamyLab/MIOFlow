{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: API details.\n",
    "output-file: train.html\n",
    "title: Train\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train\n",
       "\n",
       ">      train (model, df, groups, optimizer, n_batches=20, criterion=MMD_loss(),\n",
       ">             use_cuda=False, sample_size=(100,), sample_with_replacement=False,\n",
       ">             local_loss=True, global_loss=False, hold_one_out=False,\n",
       ">             hold_out='random', apply_losses_in_time=True, top_k=5,\n",
       ">             hinge_value=0.01, use_density_loss=True, lambda_density=1.0,\n",
       ">             autoencoder=None, use_emb=True, use_gae=False,\n",
       ">             use_gaussian:bool=True, add_noise:bool=False,\n",
       ">             noise_scale:float=0.1, logger=None, use_penalty=False,\n",
       ">             lambda_energy=1.0, reverse:bool=False)\n",
       "\n",
       "MIOFlow training loop\n",
       "\n",
       "Notes:\n",
       "    - The argument `model` must have a method `forward` that accepts two arguments\n",
       "        in its function signature:\n",
       "            ```python\n",
       "            model.forward(x, t)\n",
       "            ```\n",
       "        where, `x` is the input tensor and `t` is a `torch.Tensor` of time points (float).\n",
       "    - The training loop is divided in two parts; local (predict t+1 from t), and global (predict the entire trajectory).\n",
       "\n",
       "Arguments:\n",
       "    model (nn.Module): the initialized pytorch ODE model.\n",
       "\n",
       "    df (pd.DataFrame): the DataFrame from which to extract batch data.\n",
       "\n",
       "    groups (list): the list of the numerical groups in the data, e.g. \n",
       "        `[1.0, 2.0, 3.0, 4.0, 5.0]`, if the data has five groups.\n",
       "\n",
       "    optimizer (torch.optim): an optimizer initilized with the model's parameters.\n",
       "\n",
       "    n_batches (int): Default to '20', the number of batches from which to randomly sample each consecutive pair\n",
       "        of groups.\n",
       "\n",
       "    criterion (Callable | nn.Loss): a loss function.\n",
       "\n",
       "    use_cuda (bool): Defaults to `False`. Whether or not to send the model and data to cuda. \n",
       "\n",
       "    sample_size (tuple): Defaults to `(100, )`\n",
       "\n",
       "    sample_with_replacement (bool): Defaults to `False`. Whether or not to sample data points with replacement.\n",
       "\n",
       "    local_loss (bool): Defaults to `True`. Whether or not to use a local loss in the model.\n",
       "        See notes for more detail.\n",
       "\n",
       "    global_loss (bool): Defaults to `False`. Whether or not to use a global loss in the model.\n",
       "\n",
       "    hold_one_out (bool): Defaults to `False`. Whether or not to randomly hold one time pair\n",
       "        e.g. t_1 to t_2 out when computing the global loss.\n",
       "\n",
       "    hold_out (str | int): Defaults to `\"random\"`. Which time point to hold out when calculating the\n",
       "        global loss.\n",
       "\n",
       "    apply_losses_in_time (bool): Defaults to `True`. Applies the losses and does back propegation\n",
       "        as soon as a loss is calculated. See notes for more detail.\n",
       "\n",
       "    top_k (int): Default to '5'. The k for the k-NN used in the density loss.\n",
       "\n",
       "    hinge_value (float): Defaults to `0.01`. The hinge value for density loss.\n",
       "\n",
       "    use_density_loss (bool): Defaults to `True`. Whether or not to add density regularization.\n",
       "\n",
       "    lambda_density (float): Defaults to `1.0`. The weight for density loss.\n",
       "\n",
       "    autoencoder (NoneType|nn.Module): Default to 'None'. The full geodesic Autoencoder.\n",
       "\n",
       "    use_emb (bool): Defaults to `True`. Whether or not to use the embedding model.\n",
       "\n",
       "    use_gae (bool): Defaults to `False`. Whether or not to use the full Geodesic AutoEncoder.\n",
       "\n",
       "    use_gaussian (bool): Defaults to `True`. Whether to use random or gaussian noise.\n",
       "\n",
       "    add_noise (bool): Defaults to `False`. Whether or not to add noise.\n",
       "\n",
       "    noise_scale (float): Defaults to `0.30`. How much to scale the noise by.\n",
       "\n",
       "    logger (NoneType|Logger): Default to 'None'. The logger to record information.\n",
       "\n",
       "    use_penalty (bool): Defaults to `False`. Whether or not to use $L_e$ during training (norm of the derivative).\n",
       "\n",
       "    lambda_energy (float): Default to '1.0'. The weight of the energy penalty.\n",
       "\n",
       "    reverse (bool): Whether to train time backwards."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train\n",
       "\n",
       ">      train (model, df, groups, optimizer, n_batches=20, criterion=MMD_loss(),\n",
       ">             use_cuda=False, sample_size=(100,), sample_with_replacement=False,\n",
       ">             local_loss=True, global_loss=False, hold_one_out=False,\n",
       ">             hold_out='random', apply_losses_in_time=True, top_k=5,\n",
       ">             hinge_value=0.01, use_density_loss=True, lambda_density=1.0,\n",
       ">             autoencoder=None, use_emb=True, use_gae=False,\n",
       ">             use_gaussian:bool=True, add_noise:bool=False,\n",
       ">             noise_scale:float=0.1, logger=None, use_penalty=False,\n",
       ">             lambda_energy=1.0, reverse:bool=False)\n",
       "\n",
       "MIOFlow training loop\n",
       "\n",
       "Notes:\n",
       "    - The argument `model` must have a method `forward` that accepts two arguments\n",
       "        in its function signature:\n",
       "            ```python\n",
       "            model.forward(x, t)\n",
       "            ```\n",
       "        where, `x` is the input tensor and `t` is a `torch.Tensor` of time points (float).\n",
       "    - The training loop is divided in two parts; local (predict t+1 from t), and global (predict the entire trajectory).\n",
       "\n",
       "Arguments:\n",
       "    model (nn.Module): the initialized pytorch ODE model.\n",
       "\n",
       "    df (pd.DataFrame): the DataFrame from which to extract batch data.\n",
       "\n",
       "    groups (list): the list of the numerical groups in the data, e.g. \n",
       "        `[1.0, 2.0, 3.0, 4.0, 5.0]`, if the data has five groups.\n",
       "\n",
       "    optimizer (torch.optim): an optimizer initilized with the model's parameters.\n",
       "\n",
       "    n_batches (int): Default to '20', the number of batches from which to randomly sample each consecutive pair\n",
       "        of groups.\n",
       "\n",
       "    criterion (Callable | nn.Loss): a loss function.\n",
       "\n",
       "    use_cuda (bool): Defaults to `False`. Whether or not to send the model and data to cuda. \n",
       "\n",
       "    sample_size (tuple): Defaults to `(100, )`\n",
       "\n",
       "    sample_with_replacement (bool): Defaults to `False`. Whether or not to sample data points with replacement.\n",
       "\n",
       "    local_loss (bool): Defaults to `True`. Whether or not to use a local loss in the model.\n",
       "        See notes for more detail.\n",
       "\n",
       "    global_loss (bool): Defaults to `False`. Whether or not to use a global loss in the model.\n",
       "\n",
       "    hold_one_out (bool): Defaults to `False`. Whether or not to randomly hold one time pair\n",
       "        e.g. t_1 to t_2 out when computing the global loss.\n",
       "\n",
       "    hold_out (str | int): Defaults to `\"random\"`. Which time point to hold out when calculating the\n",
       "        global loss.\n",
       "\n",
       "    apply_losses_in_time (bool): Defaults to `True`. Applies the losses and does back propegation\n",
       "        as soon as a loss is calculated. See notes for more detail.\n",
       "\n",
       "    top_k (int): Default to '5'. The k for the k-NN used in the density loss.\n",
       "\n",
       "    hinge_value (float): Defaults to `0.01`. The hinge value for density loss.\n",
       "\n",
       "    use_density_loss (bool): Defaults to `True`. Whether or not to add density regularization.\n",
       "\n",
       "    lambda_density (float): Defaults to `1.0`. The weight for density loss.\n",
       "\n",
       "    autoencoder (NoneType|nn.Module): Default to 'None'. The full geodesic Autoencoder.\n",
       "\n",
       "    use_emb (bool): Defaults to `True`. Whether or not to use the embedding model.\n",
       "\n",
       "    use_gae (bool): Defaults to `False`. Whether or not to use the full Geodesic AutoEncoder.\n",
       "\n",
       "    use_gaussian (bool): Defaults to `True`. Whether to use random or gaussian noise.\n",
       "\n",
       "    add_noise (bool): Defaults to `False`. Whether or not to add noise.\n",
       "\n",
       "    noise_scale (float): Defaults to `0.30`. How much to scale the noise by.\n",
       "\n",
       "    logger (NoneType|Logger): Default to 'None'. The logger to record information.\n",
       "\n",
       "    use_penalty (bool): Defaults to `False`. Whether or not to use $L_e$ during training (norm of the derivative).\n",
       "\n",
       "    lambda_energy (float): Default to '1.0'. The weight of the energy penalty.\n",
       "\n",
       "    reverse (bool): Whether to train time backwards."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_ae\n",
       "\n",
       ">      train_ae (model, df, groups, optimizer, n_epochs=60, criterion=MSELoss(),\n",
       ">                dist=None, recon=True, use_cuda=False, sample_size=(100,),\n",
       ">                sample_with_replacement=False, noise_min_scale=0.09,\n",
       ">                noise_max_scale=0.15, hold_one_out:bool=False,\n",
       ">                hold_out='random')\n",
       "\n",
       "Geodesic Autoencoder training loop.\n",
       "\n",
       "Notes:\n",
       "    - We can train only the encoder the fit the geodesic distance (recon=False), or the full geodesic Autoencoder (recon=True),\n",
       "        i.e. matching the distance and reconstruction of the inputs.\n",
       "\n",
       "Arguments:\n",
       "\n",
       "    model (nn.Module): the initialized pytorch Geodesic Autoencoder model.\n",
       "\n",
       "    df (pd.DataFrame): the DataFrame from which to extract batch data.\n",
       "\n",
       "    groups (list): the list of the numerical groups in the data, e.g. \n",
       "        `[1.0, 2.0, 3.0, 4.0, 5.0]`, if the data has five groups.\n",
       "\n",
       "    optimizer (torch.optim): an optimizer initilized with the model's parameters.\n",
       "\n",
       "    n_epochs (int): Default to '60'. The number of training epochs.\n",
       "\n",
       "    criterion (torch.nn). Default to 'nn.MSELoss()'. The criterion to minimize. \n",
       "\n",
       "    dist (NoneType|Class). Default to 'None'. The distance Class with a 'fit(X)' method for a dataset 'X'. Computes the pairwise distances in 'X'.\n",
       "\n",
       "    recon (bool): Default to 'True'. Whether or not the apply the reconstruction loss. \n",
       "\n",
       "    use_cuda (bool): Defaults to `False`. Whether or not to send the model and data to cuda. \n",
       "\n",
       "    sample_size (tuple): Defaults to `(100, )`.\n",
       "\n",
       "    sample_with_replacement (bool): Defaults to `False`. Whether or not to sample data points with replacement.\n",
       "\n",
       "    noise_min_scale (float): Default to '0.0'. The minimum noise scale. \n",
       "\n",
       "    noise_max_scale (float): Default to '1.0'. The maximum noise scale. The true scale is sampled between these two bounds for each epoch. \n",
       "\n",
       "    hold_one_out (bool): Default to False, whether or not to ignore a timepoint during training.\n",
       "\n",
       "    hold_out (str|int): Default to 'random', the timepoint to hold out, either a specific element of 'groups' or a random one."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_ae\n",
       "\n",
       ">      train_ae (model, df, groups, optimizer, n_epochs=60, criterion=MSELoss(),\n",
       ">                dist=None, recon=True, use_cuda=False, sample_size=(100,),\n",
       ">                sample_with_replacement=False, noise_min_scale=0.09,\n",
       ">                noise_max_scale=0.15, hold_one_out:bool=False,\n",
       ">                hold_out='random')\n",
       "\n",
       "Geodesic Autoencoder training loop.\n",
       "\n",
       "Notes:\n",
       "    - We can train only the encoder the fit the geodesic distance (recon=False), or the full geodesic Autoencoder (recon=True),\n",
       "        i.e. matching the distance and reconstruction of the inputs.\n",
       "\n",
       "Arguments:\n",
       "\n",
       "    model (nn.Module): the initialized pytorch Geodesic Autoencoder model.\n",
       "\n",
       "    df (pd.DataFrame): the DataFrame from which to extract batch data.\n",
       "\n",
       "    groups (list): the list of the numerical groups in the data, e.g. \n",
       "        `[1.0, 2.0, 3.0, 4.0, 5.0]`, if the data has five groups.\n",
       "\n",
       "    optimizer (torch.optim): an optimizer initilized with the model's parameters.\n",
       "\n",
       "    n_epochs (int): Default to '60'. The number of training epochs.\n",
       "\n",
       "    criterion (torch.nn). Default to 'nn.MSELoss()'. The criterion to minimize. \n",
       "\n",
       "    dist (NoneType|Class). Default to 'None'. The distance Class with a 'fit(X)' method for a dataset 'X'. Computes the pairwise distances in 'X'.\n",
       "\n",
       "    recon (bool): Default to 'True'. Whether or not the apply the reconstruction loss. \n",
       "\n",
       "    use_cuda (bool): Defaults to `False`. Whether or not to send the model and data to cuda. \n",
       "\n",
       "    sample_size (tuple): Defaults to `(100, )`.\n",
       "\n",
       "    sample_with_replacement (bool): Defaults to `False`. Whether or not to sample data points with replacement.\n",
       "\n",
       "    noise_min_scale (float): Default to '0.0'. The minimum noise scale. \n",
       "\n",
       "    noise_max_scale (float): Default to '1.0'. The maximum noise scale. The true scale is sampled between these two bounds for each epoch. \n",
       "\n",
       "    hold_one_out (bool): Default to False, whether or not to ignore a timepoint during training.\n",
       "\n",
       "    hold_out (str|int): Default to 'random', the timepoint to hold out, either a specific element of 'groups' or a random one."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(train_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### training_regimen\n",
       "\n",
       ">      training_regimen (n_local_epochs, n_epochs, n_post_local_epochs, exp_dir,\n",
       ">                        model, df, groups, optimizer, n_batches=20,\n",
       ">                        criterion=MMD_loss(), use_cuda=False,\n",
       ">                        hold_one_out=False, hold_out='random',\n",
       ">                        hinge_value=0.01, use_density_loss=True, top_k=5,\n",
       ">                        lambda_density=1.0, autoencoder=None, use_emb=True,\n",
       ">                        use_gae=False, sample_size=(100,),\n",
       ">                        sample_with_replacement=False, logger=None,\n",
       ">                        add_noise=False, noise_scale=0.1, use_gaussian=True,\n",
       ">                        use_penalty=False, lambda_energy=1.0, steps=None,\n",
       ">                        plot_every=None, n_points=100, n_trajectories=100,\n",
       ">                        n_bins=100, local_losses=None, batch_losses=None,\n",
       ">                        globe_losses=None, reverse_schema=True, reverse_n=4)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_local_epochs |  |  |  |\n",
       "| n_epochs |  |  |  |\n",
       "| n_post_local_epochs |  |  |  |\n",
       "| exp_dir |  |  |  |\n",
       "| model |  |  |  |\n",
       "| df |  |  |  |\n",
       "| groups |  |  |  |\n",
       "| optimizer |  |  |  |\n",
       "| n_batches | int | 20 | BEGIN: train params |\n",
       "| criterion | MMD_loss | MMD_loss() |  |\n",
       "| use_cuda | bool | False |  |\n",
       "| hold_one_out | bool | False |  |\n",
       "| hold_out | str | random |  |\n",
       "| hinge_value | float | 0.01 |  |\n",
       "| use_density_loss | bool | True |  |\n",
       "| top_k | int | 5 |  |\n",
       "| lambda_density | float | 1.0 |  |\n",
       "| autoencoder | NoneType | None |  |\n",
       "| use_emb | bool | True |  |\n",
       "| use_gae | bool | False |  |\n",
       "| sample_size | tuple | (100,) |  |\n",
       "| sample_with_replacement | bool | False |  |\n",
       "| logger | NoneType | None |  |\n",
       "| add_noise | bool | False |  |\n",
       "| noise_scale | float | 0.1 |  |\n",
       "| use_gaussian | bool | True |  |\n",
       "| use_penalty | bool | False |  |\n",
       "| lambda_energy | float | 1.0 |  |\n",
       "| steps | NoneType | None |  |\n",
       "| plot_every | NoneType | None |  |\n",
       "| n_points | int | 100 |  |\n",
       "| n_trajectories | int | 100 |  |\n",
       "| n_bins | int | 100 |  |\n",
       "| local_losses | NoneType | None |  |\n",
       "| batch_losses | NoneType | None |  |\n",
       "| globe_losses | NoneType | None |  |\n",
       "| reverse_schema | bool | True |  |\n",
       "| reverse_n | int | 4 |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### training_regimen\n",
       "\n",
       ">      training_regimen (n_local_epochs, n_epochs, n_post_local_epochs, exp_dir,\n",
       ">                        model, df, groups, optimizer, n_batches=20,\n",
       ">                        criterion=MMD_loss(), use_cuda=False,\n",
       ">                        hold_one_out=False, hold_out='random',\n",
       ">                        hinge_value=0.01, use_density_loss=True, top_k=5,\n",
       ">                        lambda_density=1.0, autoencoder=None, use_emb=True,\n",
       ">                        use_gae=False, sample_size=(100,),\n",
       ">                        sample_with_replacement=False, logger=None,\n",
       ">                        add_noise=False, noise_scale=0.1, use_gaussian=True,\n",
       ">                        use_penalty=False, lambda_energy=1.0, steps=None,\n",
       ">                        plot_every=None, n_points=100, n_trajectories=100,\n",
       ">                        n_bins=100, local_losses=None, batch_losses=None,\n",
       ">                        globe_losses=None, reverse_schema=True, reverse_n=4)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_local_epochs |  |  |  |\n",
       "| n_epochs |  |  |  |\n",
       "| n_post_local_epochs |  |  |  |\n",
       "| exp_dir |  |  |  |\n",
       "| model |  |  |  |\n",
       "| df |  |  |  |\n",
       "| groups |  |  |  |\n",
       "| optimizer |  |  |  |\n",
       "| n_batches | int | 20 | BEGIN: train params |\n",
       "| criterion | MMD_loss | MMD_loss() |  |\n",
       "| use_cuda | bool | False |  |\n",
       "| hold_one_out | bool | False |  |\n",
       "| hold_out | str | random |  |\n",
       "| hinge_value | float | 0.01 |  |\n",
       "| use_density_loss | bool | True |  |\n",
       "| top_k | int | 5 |  |\n",
       "| lambda_density | float | 1.0 |  |\n",
       "| autoencoder | NoneType | None |  |\n",
       "| use_emb | bool | True |  |\n",
       "| use_gae | bool | False |  |\n",
       "| sample_size | tuple | (100,) |  |\n",
       "| sample_with_replacement | bool | False |  |\n",
       "| logger | NoneType | None |  |\n",
       "| add_noise | bool | False |  |\n",
       "| noise_scale | float | 0.1 |  |\n",
       "| use_gaussian | bool | True |  |\n",
       "| use_penalty | bool | False |  |\n",
       "| lambda_energy | float | 1.0 |  |\n",
       "| steps | NoneType | None |  |\n",
       "| plot_every | NoneType | None |  |\n",
       "| n_points | int | 100 |  |\n",
       "| n_trajectories | int | 100 |  |\n",
       "| n_bins | int | 100 |  |\n",
       "| local_losses | NoneType | None |  |\n",
       "| batch_losses | NoneType | None |  |\n",
       "| globe_losses | NoneType | None |  |\n",
       "| reverse_schema | bool | True |  |\n",
       "| reverse_n | int | 4 |  |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(training_regimen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklab-toy-tjnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "633393dbf1dd6081d6900ee74bcf3bc99168c1b158015580098548130ad20efc"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
