{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bfe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fad79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIOFlow.losses import MMD_loss, OT_loss, Density_loss, Local_density_loss\n",
    "from MIOFlow.utils import group_extract, sample, to_np, generate_steps\n",
    "from MIOFlow.models import ToyModel, make_model, Autoencoder\n",
    "from MIOFlow.plots import plot_comparision, plot_losses\n",
    "from MIOFlow.train import train, train_ae\n",
    "from MIOFlow.constants import ROOT_DIR, DATA_DIR, NTBK_DIR, IMGS_DIR, RES_DIR\n",
    "from MIOFlow.datasets import (\n",
    "    make_diamonds, make_swiss_roll, make_tree, make_eb_data, \n",
    "    make_dyngen_data, relabel_data\n",
    ")\n",
    "from MIOFlow.ode import NeuralODE, ODEF\n",
    "from MIOFlow.geo import GeoEmbedding, DiffusionDistance, old_DiffusionDistance\n",
    "from MIOFlow.exp import setup_exp\n",
    "from MIOFlow.eval import generate_plot_data\n",
    "\n",
    "import os, pandas as pd, numpy as np, \\\n",
    "    seaborn as sns, matplotlib as mpl, matplotlib.pyplot as plt, \\\n",
    "    torch, torch.nn as nn, pickle\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from phate import PHATE\n",
    "\n",
    "# for geodesic learning\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec27aaf",
   "metadata": {},
   "source": [
    "# Run TrajectoryNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24709689",
   "metadata": {},
   "source": [
    "**NOTE** here we are holding out one time point to see how well TJNet does interploating this missing timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = 'dyngen petals'.split()\n",
    "dataset = datasets[1]\n",
    "\n",
    "with open(os.path.expanduser(os.path.join('~/Downloads', f'{dataset}_df.pkl')), 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d0d0a",
   "metadata": {},
   "source": [
    "Here we create the datasets that are used by TJNet. Namely they are `npz` files with an `embedding_name` (here called `phate`) and another called `sample_labels` which are the time point labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4de0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepattern = lambda h: os.path.expanduser(os.path.join('~/Downloads', f'{dataset}_tjnet_ho_{int(h)}.npz'))\n",
    "\n",
    "groups = sorted(df.samples.unique())\n",
    "\n",
    "for hold_out in groups:\n",
    "    df_ho = df.drop(df[df['samples']==hold_out].index, inplace=False)\n",
    "    groups = sorted(df_ho.samples.unique())\n",
    "    \n",
    "    np.savez(\n",
    "        filepattern(hold_out), \n",
    "        phate=df_ho.drop(columns='samples').values,\n",
    "        sample_labels=df_ho.samples.astype(int).values.reshape(-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc291d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hold_out in groups:\n",
    "    !python -m TrajectoryNet.main --dataset \\\n",
    "        ~/Downloads/{dataset}_tjnet_ho_{hold_out}.npz \\\n",
    "        --embedding_name \"phate\" \\\n",
    "        --max_dim 10 \\\n",
    "        --niter 1000 \\\n",
    "        --whiten \\\n",
    "        --save ~/Downloads/{dataset}_tjnet_ho_{hold_out}\n",
    "\n",
    "    !python -m TrajectoryNet.eval --dataset \\\n",
    "        ~/Downloads/{dataset}_tjnet_ho_{hold_out}.npz \\\n",
    "        --embedding_name \"phate\" \\\n",
    "        --max_dim 10 \\\n",
    "        --niter 1000 \\\n",
    "        --vecint 1e-4 \\\n",
    "        --whiten \\\n",
    "        --save ~/Downloads/{dataset}_tjnet_ho_{hold_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8d842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
