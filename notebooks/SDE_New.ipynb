{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29493675",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a641d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIOFlow.utils import generate_steps, set_seeds, config_criterion\n",
    "from MIOFlow.models import make_model, Autoencoder\n",
    "from MIOFlow.plots import plot_comparision, plot_losses\n",
    "from MIOFlow.train import train, train_ae\n",
    "from MIOFlow.constants import ROOT_DIR, DATA_DIR, NTBK_DIR, IMGS_DIR, RES_DIR\n",
    "from MIOFlow.datasets import (\n",
    "    make_diamonds, make_swiss_roll, make_tree, make_eb_data, \n",
    "    make_dyngen_data\n",
    ")\n",
    "from MIOFlow.geo import setup_distance\n",
    "from MIOFlow.exp import setup_exp\n",
    "from MIOFlow.eval import generate_plot_data\n",
    "\n",
    "import os, pandas as pd, numpy as np, \\\n",
    "    seaborn as sns, matplotlib as mpl, matplotlib.pyplot as plt, \\\n",
    "    torch, torch.nn as nn\n",
    "from MIOFlow.train import training_regimen\n",
    "from tqdm.notebook import tqdm\n",
    "import time, pickle, scprep\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f92d08",
   "metadata": {},
   "source": [
    "# Load Petals Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b9d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 8))\n",
    "df = make_diamonds()\n",
    "df.samples -=1\n",
    "sns.scatterplot(data=df, x='d1', y='d2', hue='samples', palette='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9beaa5",
   "metadata": {},
   "source": [
    "# Train autoencoder or the geodesic embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a6173",
   "metadata": {},
   "source": [
    "#### Set seeds and check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2559b08b",
   "metadata": {},
   "source": [
    "#### Handle hold-out training condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b24ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is True if we want to holdout (or skip) one timepoint during training. It is used to test the accuracy of the trajectories on unseen data.\n",
    "hold_one_out = False\n",
    "# It can be a group number or 'random', works in tandem with hold_one_out\n",
    "hold_out = 'random'\n",
    "\n",
    "# The dimensions in the input space, it is columns - 1 because we assume one column is equal to \"samples\".\n",
    "model_features = len(df.columns) - 1\n",
    "groups = sorted(df.samples.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76803c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These determine the logic flow for training: \n",
    "#   use_emb=True use_gae=False is only the encoder to match the approximation of the geodesic.\n",
    "#   use_emb=False use_gae=True the full Geodesic Autoencoder (GAE), i.e. matching the geodesic and a reconstruction loss.\n",
    "#   use_emb=False use_gae=False Is not using the GAE.\n",
    "#   use_emb=True use_gae=True, is redundant and should raise an error. \n",
    "use_emb = True\n",
    "use_gae = False\n",
    "\n",
    "need_to_train_gae = (use_emb or use_gae) and use_emb != use_gae\n",
    "\n",
    "# If the reconstruction loss needs to be computed.\n",
    "recon = use_gae and not use_emb \n",
    "\n",
    "# These are training GAE hyperparameters needed for training\n",
    "# Distance_type in ['gaussian', 'alpha_decay'], and Gaussian scale\n",
    "distance_type = 'gaussian'\n",
    "rbf_length_scale=0.05\n",
    "dist = setup_distance(distance_type, rbf_length_scale=rbf_length_scale)\n",
    "\n",
    "#Can be changed depending on the dataset\n",
    "n_epochs_emb = 1000\n",
    "samples_size_emb = (30, )\n",
    "\n",
    "# Layers for the Geodesic Autoencoder\n",
    "gae_embedded_dim = 32\n",
    "encoder_layers = [model_features, 8, gae_embedded_dim]\n",
    "\n",
    "gae = Autoencoder(\n",
    "    encoder_layers = encoder_layers,\n",
    "    decoder_layers = encoder_layers[::-1],\n",
    "    activation='ReLU', use_cuda = use_cuda\n",
    ")\n",
    "optimizer = torch.optim.AdamW(gae.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672484bd",
   "metadata": {},
   "source": [
    "#### Actually train the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added in extra cell just for iterative programming / running of code\n",
    "#   but could be added to code block above\n",
    "\n",
    "if need_to_train_gae:\n",
    "    start_time_geo = time.time()\n",
    "\n",
    "    losses = train_ae(\n",
    "        gae, df, groups, optimizer, \n",
    "        n_epochs=n_epochs_emb, sample_size=samples_size_emb,\n",
    "        noise_min_scale=0.09, noise_max_scale=0.15, \n",
    "        dist=dist, recon=recon, use_cuda=use_cuda,\n",
    "        hold_one_out=hold_one_out, hold_out=hold_out\n",
    "    )\n",
    "    run_time_geo = time.time() - start_time_geo\n",
    "\n",
    "    print(run_time_geo)\n",
    "    autoencoder = gae\n",
    "else:\n",
    "    autoencoder = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577bf4e",
   "metadata": {},
   "source": [
    "# Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78077040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "import os, math, numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchsde\n",
    "\n",
    "class ToySDEModel(nn.Module):\n",
    "    \"\"\" \n",
    "    Neural SDE model\n",
    "        func (nn.Module): drift term.\n",
    "        gunc (nn.Module): diffusion term.\n",
    "        method (str): method of the SDE solver.\n",
    "        noise_type (str): Default to 'diagonal'. Noise to use with the diffusion.\n",
    "        sde_type (str): Default to 'ito'. Type of SDE, either 'ito' or 'stratonovich'.\n",
    "        dt (float|NoneType): Default to '0.1'. The step size. \n",
    "        use_norm (bool): Default to 'False'. Whether to keep in memory the norm of drift and diffusion. Used for the energy loss. \n",
    "        Method\n",
    "        forward (Callable)\n",
    "            x (torch.tensor): the initial sample\n",
    "            t (torch.tensor) time points where we suppose x is from t[0]\n",
    "            return the last sample or the whole seq.  \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, func, method='euler', noise_type='diagonal', sde_type='ito', \n",
    "    gunc=None, dt=0.1, use_norm=False):\n",
    "        super(ToySDEModel, self).__init__()        \n",
    "        self.func = func\n",
    "        self.method = method\n",
    "        self.noise_type = noise_type\n",
    "        self.sde_type = sde_type\n",
    "        self.gunc = gunc\n",
    "        self.alpha = None \n",
    "        self.use_norm = use_norm\n",
    "        self.norm=[]\n",
    "        self.dt = dt\n",
    "        \n",
    "    def f(self, t, y):\n",
    "        return self.func(t, y)\n",
    "\n",
    "    def g(self, t, y):\n",
    "        return self.gunc(t, y)\n",
    "\n",
    "    def forward(self, x, t, return_whole_sequence=False, dt=None):\n",
    "        if self.use_norm:\n",
    "            for time in t:\n",
    "                _temp_norm = torch.linalg.norm(self.func(time,x)) + torch.linalg.norm(self.gunc(time,x))\n",
    "                self.norm.append(_temp_norm)            \n",
    "        dt = self.dt if self.dt is not None else 0.1 if dt is None else dt        \n",
    "        x = torchsde.sdeint(self, x, t, method=self.method, dt=dt)\n",
    "        x = x[-1] if not return_whole_sequence else x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIOFlow.models import ToyODE, ToyModel\n",
    "def make_model(\n",
    "    feature_dims=5,\n",
    "    layers=[64],\n",
    "    output_dims=5,\n",
    "    activation='ReLU',\n",
    "    which='ode',\n",
    "    method='rk4',\n",
    "    rtol=None,\n",
    "    atol=None,\n",
    "    scales=None,\n",
    "    n_aug=2,\n",
    "    noise_type='diagonal', sde_type='ito',\n",
    "    use_norm=False,\n",
    "    use_cuda=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates the 'ode' model or 'sde' model or the Geodesic Autoencoder. \n",
    "    See the parameters of the respective classes.\n",
    "    \"\"\"\n",
    "    if which == 'ode':\n",
    "        ode = ToyODE(feature_dims, layers, activation,scales,n_aug)\n",
    "        model = ToyModel(ode,method,rtol, atol, use_norm=use_norm)\n",
    "    elif which == 'sde':\n",
    "        drift = ToyODE(feature_dims, layers, activation, scales=None, n_aug=n_aug)\n",
    "        diffusion = ToyODE(feature_dims, layers, activation,scales=None,n_aug=0)\n",
    "        model = ToySDEModel(drift, method, noise_type, sde_type, gunc=diffusion, use_norm=use_norm)\n",
    "    else:\n",
    "        model = ToyGeo(feature_dims, layers, output_dims, activation)\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260559ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(10)\n",
    "\n",
    "#Directory where results are saved\n",
    "exp_name = 'SDE-test'\n",
    "\n",
    "# density loss knn\n",
    "use_density_loss = False\n",
    "\n",
    "# Weight of density (not percentage of total loss)\n",
    "lambda_density = 5\n",
    "\n",
    "# For petal=LeakyReLU / dyngen=CELU\n",
    "activation = 'LeakyReLU'\n",
    "sde_type = 'ito' # The type of SDE either 'ito' or 'stratonovich'\n",
    "ode_method = 'euler'#'rk4' # if sde_type = 'stratonovich':'euler_heun', 'heun' ... if  if sde_type = 'ito': 'euler', 'milstein', 'srk'. See 'torchsde' documentation\n",
    "\n",
    "# Can change but we never really do, mostly depends on the dataset.\n",
    "layers = [16,32,16]\n",
    "use_penalty_energy = True\n",
    "lambda_energy = 0.001\n",
    "# Scale of the noise in the trajectories. Either len(groups)*[float] or None. Should be None if using an adaptative ODE solver.\n",
    "sde_scales = None #Use to add noise in the ODE model. It is replaced by the diffusion in the SDE model.\n",
    "\n",
    "if recon:    \n",
    "    model_features = gae_embedded_dim\n",
    "\n",
    "model = make_model(\n",
    "    model_features, layers, \n",
    "    activation=activation, scales=sde_scales, use_cuda=use_cuda,\n",
    "    which='sde', method=ode_method, noise_type='diagonal', use_norm=use_penalty_energy,sde_type=sde_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7da942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically \"batch size\"\n",
    "sample_size=(30, )\n",
    "\n",
    "# Training specification\n",
    "n_local_epochs = 0\n",
    "n_epochs = 10\n",
    "n_post_local_epochs = 0\n",
    "\n",
    "criterion_name = 'ot'\n",
    "criterion = config_criterion(criterion_name)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Bookkeeping variables\n",
    "batch_losses = []\n",
    "globe_losses = []\n",
    "if hold_one_out and hold_out in groups:\n",
    "    local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups) if hold_out not in [t0, t1]}\n",
    "else:\n",
    "    local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups)}\n",
    "\n",
    "# For creating output.\n",
    "n_points = 20\n",
    "n_trajectories = 100\n",
    "n_bins = 100\n",
    "\n",
    "reverse=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = {\n",
    "    'use_cuda': use_cuda,\n",
    "    'model_features': model_features,\n",
    "    'exp_name': exp_name,\n",
    "    'groups': groups,\n",
    "    'sample_size': sample_size,\n",
    "    'use_emb': use_emb,\n",
    "    'n_local_epochs': n_local_epochs,\n",
    "    'n_epochs': n_epochs,\n",
    "    'n_post_local_epochs': n_post_local_epochs,\n",
    "    'criterion_name': criterion_name,\n",
    "    'hold_one_out': hold_one_out,\n",
    "    'use_density_loss': use_density_loss,\n",
    "    'n_points': n_points,\n",
    "    'n_trajectories': n_trajectories,\n",
    "    'n_bins': n_bins,\n",
    "    'autoencoder': autoencoder,\n",
    "    'activation_ode': activation,\n",
    "    'layer': layers,\n",
    "    'lambda_density':lambda_density,\n",
    "    'use_gae': use_gae,\n",
    "    'sde_scales': sde_scales,\n",
    "    'hold_out':hold_out,\n",
    "    'encoder_layers': encoder_layers,\n",
    "    'n_epochs_emb': n_epochs_emb,\n",
    "    'samples_size_emb': samples_size_emb,\n",
    "    'recon': recon,\n",
    "    'distance_type':distance_type,\n",
    "    'rbf_length_scale':rbf_length_scale,\n",
    "    'reverse': reverse\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94993d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir, logger = setup_exp(RES_DIR, opts, exp_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579660d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "local_losses, batch_losses, globe_losses = training_regimen(\n",
    "    # local, global, local train structure\n",
    "    n_local_epochs=n_local_epochs, \n",
    "    n_epochs=n_epochs, \n",
    "    n_post_local_epochs=n_post_local_epochs,\n",
    "    \n",
    "    # where results are stored\n",
    "    exp_dir=exp_dir, \n",
    "\n",
    "    # BEGIN: train params\n",
    "    model=model, df=df, groups=groups, optimizer=optimizer, \n",
    "    criterion=criterion, use_cuda=use_cuda,\n",
    "    \n",
    "    hold_one_out=hold_one_out, hold_out=hold_out,\n",
    "    \n",
    "    use_density_loss=use_density_loss, \n",
    "    lambda_density=lambda_density,\n",
    "    use_penalty=use_penalty_energy, lambda_energy=lambda_energy,\n",
    "    \n",
    "    autoencoder=autoencoder, use_emb=use_emb, use_gae=use_gae, \n",
    "    \n",
    "    sample_size=sample_size, logger=logger,\n",
    "    # END: train params\n",
    "\n",
    "    plot_every=1,\n",
    "    n_points=n_points, n_trajectories=n_trajectories, n_bins=n_bins, \n",
    "#     local_losses=local_losses, batch_losses=batch_losses, globe_losses=globe_losses,\n",
    "    reverse_schema=reverse\n",
    ")\n",
    "run_time = time.time() - start_time + run_time_geo if use_emb or use_gae else time.time() - start_time\n",
    "logger.info(f'Total run time: {np.round(run_time, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(\n",
    "    local_losses, batch_losses, globe_losses, \n",
    "    save=True, path=exp_dir, file='losses.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated, trajectories = generate_plot_data(\n",
    "    model, df, n_points, n_trajectories, n_bins, use_cuda=use_cuda, samples_key='samples', logger=logger,\n",
    "    autoencoder=autoencoder, recon=recon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparision(\n",
    "    df, generated, trajectories,\n",
    "    palette = 'viridis', df_time_key='samples',\n",
    "    save=True, path=exp_dir, file='2d_comparision.png',\n",
    "    x='d1', y='d2', z='d3', is_3d=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df048999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
