{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab964908",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8bb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIOFlow.utils import generate_steps, set_seeds, config_criterion\n",
    "from MIOFlow.models import make_model, Autoencoder\n",
    "from MIOFlow.plots import plot_comparision, plot_losses\n",
    "from MIOFlow.train import train_ae, training_regimen\n",
    "from MIOFlow.constants import ROOT_DIR, DATA_DIR, NTBK_DIR, IMGS_DIR, RES_DIR\n",
    "from MIOFlow.datasets import (\n",
    "    make_diamonds, make_swiss_roll, make_tree, make_eb_data, \n",
    "    make_dyngen_data\n",
    ")\n",
    "from MIOFlow.geo import setup_distance\n",
    "from MIOFlow.exp import setup_exp\n",
    "from MIOFlow.eval import generate_plot_data\n",
    "\n",
    "import os, pandas as pd, numpy as np, \\\n",
    "    seaborn as sns, matplotlib as mpl, matplotlib.pyplot as plt, \\\n",
    "    torch, torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d191189",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phate_dims = 5\n",
    "df = make_dyngen_data(phate_dims=phate_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e731bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 8), dpi=300)\n",
    "sns.scatterplot(data=df, x='d1', y='d2', hue='samples', palette='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8dc35b",
   "metadata": {},
   "source": [
    "# Train autoencoder or the geodesic embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bfa25",
   "metadata": {},
   "source": [
    "#### Set seeds and check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a86628",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341dd47",
   "metadata": {},
   "source": [
    "#### Handle hold-out training condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c56d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is True if we want to holdout (or skip) one timepoint during training. It is used to test the accuracy of the trajectories on unseen data.\n",
    "hold_one_out = True\n",
    "# It can be a group number or 'random', works in tandem with hold_one_out\n",
    "hold_out = 5\n",
    "\n",
    "# The dimensions in the input space, it is columns - 1 because we assume one column is equal to \"samples\".\n",
    "model_features = len(df.columns) - 1\n",
    "groups = sorted(df.samples.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72828508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These determine the logic flow for training: \n",
    "#   use_emb=True use_gae=False is only the encoder to match the approximation of the geodesic.\n",
    "#   use_emb=False use_gae=True the full Geodesic Autoencoder (GAE), i.e. matching the geodesic and a reconstruction loss.\n",
    "#   use_emb=False use_gae=False Is not using the GAE.\n",
    "#   use_emb=True use_gae=True, is redundant and should raise an error. \n",
    "use_emb = False\n",
    "use_gae = False\n",
    "\n",
    "need_to_train_gae = (use_emb or use_gae) and use_emb != use_gae\n",
    "\n",
    "# If the reconstruction loss needs to be computed.\n",
    "recon = use_gae and not use_emb \n",
    "\n",
    "# These are training GAE hyperparameters needed for training\n",
    "# Distance_type in ['gaussian', 'alpha_decay'], and Gaussian scale\n",
    "distance_type = 'gaussian'\n",
    "rbf_length_scale=0.5\n",
    "knn=5\n",
    "t_max=5\n",
    "dist = setup_distance(distance_type, rbf_length_scale=rbf_length_scale, knn=knn, t_max=t_max)\n",
    "\n",
    "#Can be changed depending on the dataset\n",
    "n_epochs_emb = 1500\n",
    "samples_size_emb = (30, )\n",
    "\n",
    "# Layers for the Geodesic Autoencoder\n",
    "gae_embedded_dim = 32\n",
    "encoder_layers = [model_features, 8, gae_embedded_dim]\n",
    "\n",
    "gae = Autoencoder(\n",
    "    encoder_layers = encoder_layers,\n",
    "    decoder_layers = encoder_layers[::-1],\n",
    "    activation='ReLU', use_cuda = use_cuda\n",
    ")\n",
    "optimizer = torch.optim.AdamW(gae.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7768c878",
   "metadata": {},
   "source": [
    "#### Actually train the GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f2f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added in extra cell just for iterative programming / running of code\n",
    "#   but could be added to code block above\n",
    "\n",
    "if need_to_train_gae:\n",
    "    start_time_geo = time.time()\n",
    "\n",
    "    losses = train_ae(\n",
    "        gae, df, groups, optimizer, \n",
    "        n_epochs=n_epochs_emb, sample_size=samples_size_emb,\n",
    "        noise_min_scale=0.09, noise_max_scale=0.15, \n",
    "        dist=dist, recon=recon, use_cuda=use_cuda,\n",
    "        hold_one_out=hold_one_out, hold_out=hold_out\n",
    "    )\n",
    "    run_time_geo = time.time() - start_time_geo\n",
    "\n",
    "    print(run_time_geo)\n",
    "    autoencoder = gae\n",
    "else:\n",
    "    autoencoder = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef704313",
   "metadata": {},
   "source": [
    "# Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81445197",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(10)\n",
    "\n",
    "#Directory where results are saved\n",
    "exp_name = 'holdout_dyn'\n",
    "\n",
    "# density loss knn\n",
    "use_density_loss = True\n",
    "\n",
    "# Weight of density (not percentage of total loss)\n",
    "lambda_density = 5\n",
    "\n",
    "# For petal=LeakyReLU / dyngen=CELU\n",
    "activation = 'CELU'\n",
    "\n",
    "# Can change but we never really do, mostly depends on the dataset.\n",
    "layers = [16,32,16]\n",
    "\n",
    "# Scale of the noise in the trajectories. Either len(groups)*[float] or None. Should be None if using an adaptative ODE solver.\n",
    "sde_scales = len(groups)*[0.2] \n",
    "\n",
    "if recon:    \n",
    "    model_features = gae_embedded_dim\n",
    "\n",
    "model = make_model(\n",
    "    model_features, layers, \n",
    "    activation=activation, scales=sde_scales, use_cuda=use_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically \"batch size\"\n",
    "sample_size=(60, )\n",
    "\n",
    "# Training specification\n",
    "n_local_epochs = 20\n",
    "n_epochs = 80\n",
    "n_post_local_epochs = 0\n",
    "\n",
    "# Using the reverse trajectories to train\n",
    "reverse_schema = True\n",
    "# each reverse_n epoch\n",
    "reverse_n = 2\n",
    "\n",
    "\n",
    "criterion_name = 'ot'\n",
    "criterion = config_criterion(criterion_name)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "# Bookkeeping variables\n",
    "batch_losses = []\n",
    "globe_losses = []\n",
    "if hold_one_out and hold_out in groups:\n",
    "    groups_ho = [g for g in groups if g != hold_out]\n",
    "    local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups_ho)}\n",
    "else:\n",
    "    local_losses = {f'{t0}:{t1}':[] for (t0, t1) in generate_steps(groups)}\n",
    "\n",
    "# For creating output.\n",
    "n_points = 100\n",
    "n_trajectories = 100\n",
    "n_bins = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19528d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = {\n",
    "    'phate_dims': phate_dims,\n",
    "    'use_cuda': use_cuda,\n",
    "    'model_features': model_features,\n",
    "    'exp_name': exp_name,\n",
    "    'groups': groups,\n",
    "    'sample_size': sample_size,\n",
    "    'use_emb': use_emb,\n",
    "    'n_local_epochs': n_local_epochs,\n",
    "    'n_epochs': n_epochs,\n",
    "    'n_post_local_epochs': n_post_local_epochs,\n",
    "    'criterion_name': criterion_name,\n",
    "    'hold_one_out': hold_one_out,\n",
    "    'use_density_loss': use_density_loss,\n",
    "    'n_points': n_points,\n",
    "    'n_trajectories': n_trajectories,\n",
    "    'n_bins': n_bins,\n",
    "    'autoencoder': autoencoder,\n",
    "    'activation_ode': activation,\n",
    "    'layer': layers,\n",
    "    'lambda_density':lambda_density,\n",
    "    'use_gae': use_gae,\n",
    "    'sde_scales': sde_scales,\n",
    "    'hold_out':hold_out,\n",
    "    'encoder_layers': encoder_layers,\n",
    "    'n_epochs_emb': n_epochs_emb,\n",
    "    'samples_size_emb': samples_size_emb,\n",
    "    'recon': recon,\n",
    "    'distance_type':distance_type,\n",
    "    'rbf_length_scale':rbf_length_scale,\n",
    "    'reverse_schema': reverse_schema,\n",
    "    'reverse_n': reverse_n,\n",
    "    'knn': knn,\n",
    "    't_max': t_max\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0adfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir, logger = setup_exp(RES_DIR, opts, exp_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "local_losses, batch_losses, globe_losses = training_regimen(\n",
    "    # local, global, local train structure\n",
    "    n_local_epochs=n_local_epochs, \n",
    "    n_epochs=n_epochs, \n",
    "    n_post_local_epochs=n_post_local_epochs,\n",
    "    \n",
    "    # where results are stored\n",
    "    exp_dir=exp_dir, \n",
    "\n",
    "    # BEGIN: train params\n",
    "    model=model, df=df, groups=groups, optimizer=optimizer, \n",
    "    criterion=criterion, use_cuda=use_cuda,\n",
    "    \n",
    "    hold_one_out=hold_one_out, hold_out=hold_out,\n",
    "    \n",
    "    use_density_loss=use_density_loss, \n",
    "    lambda_density=lambda_density,\n",
    "    \n",
    "    autoencoder=autoencoder, use_emb=use_emb, use_gae=use_gae, \n",
    "    \n",
    "    sample_size=sample_size, logger=logger,\n",
    "    reverse_schema=reverse_schema, reverse_n=reverse_n,\n",
    "    # END: train params\n",
    "\n",
    "    plot_every=5,\n",
    "    n_points=n_points, n_trajectories=n_trajectories, n_bins=n_bins, \n",
    "    #local_losses=local_losses, batch_losses=batch_losses, globe_losses=globe_losses\n",
    ")\n",
    "run_time = time.time() - start_time + run_time_geo if use_emb or use_gae else time.time() - start_time\n",
    "logger.info(f'Total run time: {np.round(run_time, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(\n",
    "    local_losses, batch_losses, globe_losses, \n",
    "    save=True, path=exp_dir, file='losses.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c71ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated, trajectories = generate_plot_data(\n",
    "    model, df, n_points, n_trajectories, n_bins, use_cuda=use_cuda, samples_key='samples', logger=logger,\n",
    "    autoencoder=autoencoder, recon=recon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparision(\n",
    "    df, generated, trajectories,\n",
    "    palette = 'viridis', df_time_key='samples',\n",
    "    save=True, path=exp_dir, file='2d_comparision.png',\n",
    "    x='d1', y='d2', z='d3', is_3d=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparision(\n",
    "    df, generated, trajectories,\n",
    "    palette = 'viridis', df_time_key='samples',\n",
    "    save=True, path=exp_dir, file='3d_comparision.png',\n",
    "    x='d1', y='d2', z='d3', is_3d=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the trajectories and generated points\n",
    "np.save(os.path.join(exp_dir,'trajectories_leave{}_noemb.npy'.format(hold_out)),trajectories)\n",
    "np.save(os.path.join(exp_dir,'generated_leave{}_noemb.npy'.format(hold_out)),generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary fix for the logger\n",
    "import logging\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the evolution of the scales before/after training. \n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbbd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.load()\n",
    "from MIOFlow.utils import group_extract, sample\n",
    "import ot\n",
    "set_seeds(10)\n",
    "xs = gen[1]\n",
    "xt = group_extract(df,2)\n",
    "xs.shape,xt.shape\n",
    "# from MIOFlow.losses import MMD_loss\n",
    "# mmd = MMD_loss()\n",
    "# mmd.forward(torch.tensor(xs),torch.tensor(xt))\n",
    "a = torch.tensor(ot.unif(xs.shape[0]))\n",
    "b = torch.tensor(ot.unif(xt.shape[0]))\n",
    "M = ot.dist(xs, xt, metric='euclidean')\n",
    "ot.emd2(a, b, M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.15 64-bit ('sklab-toy-tjnet')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
